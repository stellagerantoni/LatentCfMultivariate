{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stellagerantoni/LatentCfMultivariate/blob/main/FaceDetection_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/stellagerantoni/LatentCfMultivariate"
      ],
      "metadata": {
        "id": "1fwOXGEl_ine",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d875ff4b-71c7-4737-8987-701e3116f54e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LatentCfMultivariate'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 212 (delta 80), reused 36 (delta 36), pack-reused 105\u001b[K\n",
            "Receiving objects: 100% (212/212), 12.40 MiB | 23.64 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wildboar\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q stumpy\n",
        "!pip install -q fastdtw\n",
        "!pip install aeon"
      ],
      "metadata": {
        "id": "89L3kts7CCan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b873fc7-0514-40e7-8eeb-53d127c65875"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.1/169.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m926.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aeon\n",
            "  Downloading aeon-0.6.0-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (23.2.0)\n",
            "Collecting deprecated>=1.2.13 (from aeon)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numba>=0.55 in /usr/local/lib/python3.10/dist-packages (from aeon) (0.58.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (23.2)\n",
            "Requirement already satisfied: pandas<2.1.0,>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn<1.4.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.2.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.11.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->aeon) (1.14.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55->aeon) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.0,>=1.5.3->aeon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.0,>=1.5.3->aeon) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.0,>=1.0.0->aeon) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.0,>=1.0.0->aeon) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.1.0,>=1.5.3->aeon) (1.16.0)\n",
            "Installing collected packages: deprecated, aeon\n",
            "Successfully installed aeon-0.6.0 deprecated-1.2.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "from aeon.datasets import load_classification\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "%cd '/content/LatentCfMultivariate'\n",
        "from _guided import ModifiedLatentCF\n",
        "from help_functions import *\n",
        "from keras_models import *"
      ],
      "metadata": {
        "id": "Bdkpan5lCGRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5982460-4744-449f-ceb3-eac4f822b448"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LatentCfMultivariate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n",
        "RANDOM_STATE = 39"
      ],
      "metadata": {
        "id": "GJE1AxFnE51S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ACTUALL CODE**\n",
        "datasets available : 'Heartbeat', 'SelfRegulationSCP1'"
      ],
      "metadata": {
        "id": "6vVfmpyuZyC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset):\n",
        "  X, y = load_classification(dataset)\n",
        "  if dataset == 'FaceDetection':\n",
        "    pos = '1'\n",
        "    neg = '0'\n",
        "\n",
        "\n",
        "  print(\" Shape of X = \", X.shape)\n",
        "  print(\" Shape of y = \", y.shape)\n",
        "  #print(\" Meta data = \", meta_data)\n",
        "  # Convert positive and negative labels to 1 and 0\n",
        "  pos_label, neg_label = 1, 0\n",
        "  if pos != pos_label:\n",
        "      y[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "  if neg != neg_label:\n",
        "      y[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "  y = y.astype(int)\n",
        "  print(f\"\\n X[:1] = \\n{X[:1]}\")\n",
        "  return X,y\n"
      ],
      "metadata": {
        "id": "Ya5WxsJ8TSgZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 39\n",
        "X, y = load_dataset('FaceDetection')\n",
        "X = X.transpose(0,2,1)\n",
        "\n",
        "#print(f'data imformation = {data_information}')\n",
        "#keep half the dataset because it is too big\n",
        "X,X_through,y,y_through = train_test_split(X, y, test_size=0.5, random_state=RANDOM_STATE, stratify=y)\n",
        "print(f'shape of X = {X.shape}')\n",
        "print(f'shape of y = {y.shape}')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
        "print(f'shape of X train = {X_train.shape}')\n",
        "print(f'shape of y train = {y_train.shape}')"
      ],
      "metadata": {
        "id": "W4m9pwqyVY1b",
        "outputId": "ce2458fc-4594-4489-cc04-9029e49588df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Shape of X =  (9414, 144, 62)\n",
            " Shape of y =  (9414,)\n",
            "\n",
            " X[:1] = \n",
            "[[[-0.07545  -0.336703 -0.278238 ... -0.411078 -1.016122 -1.161735]\n",
            "  [ 0.05608  -0.128013 -0.323847 ... -2.114348  0.208789 -0.509533]\n",
            "  [-0.824537 -0.746068 -0.482871 ... -0.929275 -1.007972 -0.292018]\n",
            "  ...\n",
            "  [-0.56758  -1.073942 -1.136367 ... -0.541122 -0.765445 -1.73308 ]\n",
            "  [-0.23404   0.104291  0.327425 ... -1.458801  0.318952  1.854007]\n",
            "  [-0.356189 -0.511199 -0.483072 ... -1.177502 -0.728301 -0.400074]]]\n",
            "shape of X = (4707, 62, 144)\n",
            "shape of y = (4707,)\n",
            "shape of X train = (3765, 62, 144)\n",
            "shape of y train = (3765,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upsample the minority class\n",
        "\n",
        "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "print(f'before: {class_counts}')\n",
        "X_train,y_train = upsample_minority_multivariate(X_train,y_train)\n",
        "X,y = upsample_minority_multivariate(X, y)\n",
        "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "print(f'after: {class_counts}')"
      ],
      "metadata": {
        "id": "Q2v7QdrHieA8",
        "outputId": "e5a02670-2995-4415-b975-c8ae5434feb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before: [1883 1882]\n",
            "after: [1883 1883]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing and Padding all our data\n",
        "#Padding needed for autoencoder\n",
        "\n",
        "n_training,n_timesteps, n_features= X_train.shape\n",
        "\n",
        "X, trained_scaler =  normalize_multivariate(data=X, n_timesteps=n_timesteps, n_features = n_features)\n",
        "X_train_processed, trained_scaler =  normalize_multivariate(data=X_train, n_timesteps=n_timesteps, n_features = n_features)\n",
        "X_test_processed, _ =  normalize_multivariate(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler, n_features = n_features)\n",
        "\n",
        "X, padding_size = conditional_pad_multivariate(X)\n",
        "X_train_processed_padded, padding_size = conditional_pad_multivariate(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad_multivariate(X_test_processed)\n",
        "\n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "print(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n",
        "\n",
        "#check the processing (0,1) min should be min 0 and max should be max 1\n",
        "print(f\"\\nmin value = {np.min(X_train)}, max value = {np.max(X_train)}\")\n",
        "print(f\"min value normalized = {np.min(X_train_processed)}, max value normalized= {np.max(X_train_processed)}\")\n",
        "\n",
        "#check that padding paddes the right dimention\n",
        "print(f\"\\nX_train.shape = {X_train.shape}\" )\n",
        "print(f\"X_train_processed_padded.shape = {X_train_processed_padded.shape}\")\n"
      ],
      "metadata": {
        "id": "00Q9QjKy7wEZ",
        "outputId": "002bdc73-a23f-4f84-db50-b048809f21d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data pre-processed, original #timesteps=62, padded #timesteps=64.\n",
            "\n",
            "min value = -24.327769, max value = 24.326942\n",
            "min value normalized = 0.0, max value normalized= 1.0000000000000002\n",
            "\n",
            "X_train.shape = (3766, 62, 144)\n",
            "X_train_processed_padded.shape = (3766, 64, 144)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_validation, y_train, y_validation = train_test_split(X_train_processed_padded, y_train, test_size=0.2, random_state=RANDOM_STATE, stratify=y_train)"
      ],
      "metadata": {
        "id": "1mYFZmsvtB9q"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the two forms of labels needed\n",
        "#-the y_classes (1,0,1,0,...)\n",
        "#-the y (one hot encoded)\n",
        "\n",
        "print(f'X_train = {X_train.shape}')\n",
        "print(f'X_validation = {X_validation.shape}')\n",
        "print(f'X_test = {X_test.shape}')\n",
        "\n",
        "y_classes = y\n",
        "y_train_classes = y_train\n",
        "y_validation_classes = y_validation\n",
        "y_test_classes = y_test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, len(np.unique(y)))\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_validation = to_categorical(y_validation, len(np.unique(y_validation)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))\n",
        "\n",
        "print(f'\\ny_train_classes = {y_train_classes.shape}, y_validation_classes = {y_validation_classes.shape}, y_test_classes = {y_test_classes.shape}')\n",
        "print(f'y_train = {y_train.shape}, y_validation = {y_validation.shape}, y_test= {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9b2F-vytxzU",
        "outputId": "27d61081-3f69-4501-efea-0e260631f211"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train = (3012, 64, 144)\n",
            "X_validation = (754, 64, 144)\n",
            "X_test = (942, 62, 144)\n",
            "\n",
            "y_train_classes = (3012,), y_validation_classes = (754,), y_test_classes = (942,)\n",
            "y_train = (3012, 2), y_validation = (754, 2), y_test= (942, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Classifier(\n",
        "    n_timesteps, n_features, n_conv_layers=1, add_dense_layer=True, n_output=2\n",
        "):\n",
        "    # https://keras.io/examples/timeseries/timeseries_classification_from_scratch/\n",
        "\n",
        "    input_shape = ( n_timesteps,n_features)\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape, dtype=\"float32\")\n",
        "\n",
        "    if add_dense_layer:\n",
        "        x = keras.layers.Dense(128, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(inputs)\n",
        "    else:\n",
        "        x = inputs\n",
        "\n",
        "    for i in range(n_conv_layers):\n",
        "        x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "        x = keras.layers.ReLU()(x)\n",
        "\n",
        "    x = keras.layers.MaxPooling1D(pool_size=2, padding=\"same\")(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "\n",
        "    if n_output >= 2:\n",
        "        outputs = keras.layers.Dense(n_output,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation=\"softmax\")(x)\n",
        "    else:\n",
        "        outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    classifier = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return classifier"
      ],
      "metadata": {
        "id": "WoMahiopQqxb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ## LatentCF++ models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "###############################################\n",
        "# ### 1dCNN classifier\n",
        "\n",
        "cnnClassifier = Classifier(\n",
        "    n_timesteps_padded, n_features, n_output=2, add_dense_layer = False\n",
        ")\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "cnnClassifier.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=15, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for LSTM-FCN classifier:\")\n",
        "classifier_history = cnnClassifier.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=150,\n",
        "    batch_size=12,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_validation, y_validation),\n",
        "    callbacks=[early_stopping_accuracy],\n",
        ")\n",
        "\n",
        "y_pred = cnnClassifier.predict(X_test_processed_padded)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "print(f\"LSTM-FCN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "    confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "    index=[\"True:1\", \"True:0\"],\n",
        "    columns=[\"Pred:1\", \"Pred:0\"],\n",
        ")\n",
        "print(confusion_matrix_df)\n"
      ],
      "metadata": {
        "id": "yNkKTXe6IIyF",
        "outputId": "0b343907-d742-4f8b-c8fe-622443e68ac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training log for LSTM-FCN classifier:\n",
            "Epoch 1/150\n",
            "251/251 [==============================] - 7s 7ms/step - loss: 0.7165 - accuracy: 0.5697 - val_loss: 0.8381 - val_accuracy: 0.5000\n",
            "Epoch 2/150\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5930 - accuracy: 0.7178 - val_loss: 0.7679 - val_accuracy: 0.5027\n",
            "Epoch 3/150\n",
            "251/251 [==============================] - 1s 6ms/step - loss: 0.4858 - accuracy: 0.7985 - val_loss: 0.6333 - val_accuracy: 0.6724\n",
            "Epoch 4/150\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8612 - val_loss: 1.3723 - val_accuracy: 0.5040\n",
            "Epoch 5/150\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.3287 - accuracy: 0.9017 - val_loss: 1.0553 - val_accuracy: 0.5345\n",
            "Epoch 6/150\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.2693 - accuracy: 0.9376 - val_loss: 1.7538 - val_accuracy: 0.5080\n",
            "Epoch 7/150\n",
            "251/251 [==============================] - 2s 6ms/step - loss: 0.2304 - accuracy: 0.9552 - val_loss: 0.4558 - val_accuracy: 0.8263\n",
            "Epoch 8/150\n",
            "251/251 [==============================] - 2s 7ms/step - loss: 0.1872 - accuracy: 0.9781 - val_loss: 0.7628 - val_accuracy: 0.6724\n",
            "Epoch 9/150\n",
            "251/251 [==============================] - 1s 6ms/step - loss: 0.1608 - accuracy: 0.9884 - val_loss: 1.8307 - val_accuracy: 0.5265\n",
            "Epoch 10/150\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.1418 - accuracy: 0.9934 - val_loss: 0.4452 - val_accuracy: 0.8422\n",
            "Epoch 11/150\n",
            "251/251 [==============================] - 1s 6ms/step - loss: 0.1208 - accuracy: 0.9987 - val_loss: 1.5447 - val_accuracy: 0.5544\n",
            "Epoch 12/150\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.1120 - accuracy: 0.9993 - val_loss: 0.4135 - val_accuracy: 0.8820\n",
            "Epoch 13/150\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.1013 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.8528\n",
            "Epoch 14/150\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.0995 - accuracy: 0.9993 - val_loss: 0.6920 - val_accuracy: 0.7493\n",
            "Epoch 15/150\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.0901 - accuracy: 0.9997 - val_loss: 0.6561 - val_accuracy: 0.7268\n",
            "Epoch 16/150\n",
            "251/251 [==============================] - 2s 6ms/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.8660\n",
            "Epoch 17/150\n",
            "251/251 [==============================] - 2s 8ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.8263\n",
            "Epoch 18/150\n",
            "251/251 [==============================] - 2s 8ms/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.4675 - val_accuracy: 0.8329\n",
            "Epoch 19/150\n",
            "251/251 [==============================] - 2s 7ms/step - loss: 0.0786 - accuracy: 0.9993 - val_loss: 1.8190 - val_accuracy: 0.5385\n",
            "Epoch 20/150\n",
            "251/251 [==============================] - 2s 7ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.7944\n",
            "Epoch 21/150\n",
            "251/251 [==============================] - 1s 6ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.8660\n",
            "Epoch 22/150\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 1.1056 - val_accuracy: 0.6300\n",
            "Epoch 23/150\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.8488\n",
            "Epoch 24/150\n",
            "251/251 [==============================] - 1s 6ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.8541\n",
            "Epoch 25/150\n",
            "251/251 [==============================] - 2s 8ms/step - loss: 0.0736 - accuracy: 0.9954 - val_loss: 0.9278 - val_accuracy: 0.6578\n",
            "Epoch 26/150\n",
            "251/251 [==============================] - 2s 7ms/step - loss: 0.0662 - accuracy: 0.9997 - val_loss: 0.4508 - val_accuracy: 0.8554\n",
            "Epoch 27/150\n",
            "251/251 [==============================] - 1s 6ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.8714\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "LSTM-FCN classifier trained, with validation accuracy 0.743099787685775.\n",
            "        Pred:1  Pred:0\n",
            "True:1     342     129\n",
            "True:0     113     358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder( n_timesteps_padded,n_features,32)\n",
        "optimizer = keras.optimizers.Adam(lr=0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, restore_best_weights=True)\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    batch_size=12,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    validation_data=(X_validation, X_validation),\n",
        "    callbacks=[early_stopping])\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history['val_loss'])\n",
        "print(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")\n"
      ],
      "metadata": {
        "id": "E6IxH8BLEKFG",
        "outputId": "33658a83-7d1f-48ec-e182-e4e288f09c78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 64, 144)\n",
            "(None, 64, 32)\n",
            "(None, 32, 32)\n",
            "(None, 32, 16)\n",
            "(None, 16, 16)\n",
            "(None, 16, 16)\n",
            "(None, 32, 16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 32, 32)\n",
            "(None, 64, 32)\n",
            "(None, 64, 144)\n",
            "Training log for 1dCNN autoencoder:\n",
            "Epoch 1/50\n",
            "251/251 - 5s - loss: 0.0144 - val_loss: 0.0016 - 5s/epoch - 18ms/step\n",
            "Epoch 2/50\n",
            "251/251 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 9ms/step\n",
            "Epoch 3/50\n",
            "251/251 - 2s - loss: 0.0011 - val_loss: 0.0012 - 2s/epoch - 8ms/step\n",
            "Epoch 4/50\n",
            "251/251 - 2s - loss: 0.0010 - val_loss: 0.0011 - 2s/epoch - 7ms/step\n",
            "Epoch 5/50\n",
            "251/251 - 2s - loss: 0.0010 - val_loss: 0.0011 - 2s/epoch - 7ms/step\n",
            "Epoch 6/50\n",
            "251/251 - 2s - loss: 0.0010 - val_loss: 0.0011 - 2s/epoch - 7ms/step\n",
            "Epoch 7/50\n",
            "251/251 - 2s - loss: 0.0010 - val_loss: 0.0011 - 2s/epoch - 7ms/step\n",
            "1dCNN autoencoder trained, with validation loss: 0.001126678311266005.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gettting the Global weights, needed for counterfactuals\n",
        "\n",
        "from _guided import get_global_weights\n",
        "from help_functions import evaluate\n",
        "pos_label = 1\n",
        "neg_label = 0\n",
        "\n",
        "step_weights = get_global_weights(\n",
        "        X,\n",
        "        y_classes,\n",
        "        cnnClassifier,\n",
        "        n_timesteps= n_timesteps,\n",
        "        n_features=n_features,\n",
        "        random_state=RANDOM_STATE,\n",
        ")\n"
      ],
      "metadata": {
        "id": "hysd9dxSsx9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3610cf11-8794-49f1-a283-3ca8c3a8b2ae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 4ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n",
            "148/148 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step_weights"
      ],
      "metadata": {
        "id": "3WcwnNgc3RdP",
        "outputId": "29abf455-1a39-4b74-aa2f-ddbb4a80ee02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5,tolerance=1e-6, max_iter=500, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),autoencoder = autoencoder,\n",
        "    pred_margin_weight=0.7, step_weights = step_weights, random_state= RANDOM_STATE)\n",
        "cf_model.fit(cnnClassifier)\n",
        "\n",
        "y_neg = y_classes[y_classes == 0][10:15]\n",
        "X_neg = X[y_classes == 0][10:15]\n",
        "\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses, weights = cf_model.transform(X_neg, y_neg) #self, x, pred_label\n",
        "cf_pred_labels = cnnClassifier.predict(cf_embeddings)[:,1]# predicted probabilities of CFs\n",
        "for idx in range(cf_pred_labels.shape[0]):\n",
        "  if cf_pred_labels[idx] > 0.5:\n",
        "    cf_pred_labels[idx] = 1\n",
        "  else:\n",
        "    cf_pred_labels[idx] = 0\n",
        "\n",
        "print(f'Transformation_finished with validity_score = {validity_score(y_neg,cf_pred_labels)}')"
      ],
      "metadata": {
        "id": "f-Xy39aj8q9S",
        "outputId": "adcc05a1-9cdc-4812-a7d6-fd273c153269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 samples been transformed.\n",
            "5 samples been transformed, in total.\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "Transformation_finished with validity_score = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating proximity\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "total = 0\n",
        "probability = 0.5\n",
        "for idx in range(cf_embeddings.shape[0]):\n",
        "    counterfactual = cf_embeddings[idx,np.newaxis]\n",
        "    prediction = cnnClassifier.predict(counterfactual)[:, 1]\n",
        "    dist = (prediction - probability)\n",
        "    total +=dist\n",
        "mean_mse = total /cf_embeddings.shape[0]\n"
      ],
      "metadata": {
        "id": "ZkPSSHScmi2p",
        "outputId": "5822912c-e501-430d-a77e-8621c806a34c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The Mean MSE of the data is: {mean_mse} \")"
      ],
      "metadata": {
        "id": "6FXZX1A-5Er1",
        "outputId": "611e9de9-e6bb-4020-df39-4162a5030e3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean MSE of the data is: [0.00062653] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating proximity\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "total = 0\n",
        "probability = 0.5\n",
        "for idx in range(cf_embeddings.shape[0]):\n",
        "    counterfactual = cf_embeddings[idx,np.newaxis]\n",
        "    prediction = cnnClassifier.predict(counterfactual)[:, 1]\n",
        "    dist = abs(prediction - probability)\n",
        "    total +=dist\n",
        "mean_mse = total /cf_embeddings.shape[0]\n"
      ],
      "metadata": {
        "id": "AcUwDKnZmj6b",
        "outputId": "32a82126-aaa0-43a9-e35c-87f3714afd01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The Absolute Mean MSE of the data is: {mean_mse} \")"
      ],
      "metadata": {
        "id": "1x5s2_8H5F3w",
        "outputId": "ba93ea31-5ae6-4298-d678-88315766a545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Absolute Mean MSE of the data is: [0.00062653] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Proximity\n",
        "def euclidean_distance(X, cf_samples):\n",
        "    paired_distances = np.linalg.norm(X - cf_samples, axis=1)\n",
        "    return np.mean(paired_distances)\n",
        "euclidean_distance(X_neg, cf_embeddings)"
      ],
      "metadata": {
        "id": "50Hed3JXrm1Z",
        "outputId": "6d9b6a77-f5f7-4741-b503-24a2729fd081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6309590391658204"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_paddings(cf_samples, padding_size):\n",
        "    if padding_size != 0:\n",
        "        # use np.squeeze() to cut the last time-series dimension, for evaluation\n",
        "        cf_samples = np.squeeze(cf_samples[:, :-padding_size, :])\n",
        "    else:\n",
        "        cf_samples = np.squeeze(cf_samples)\n",
        "    return cf_samples"
      ],
      "metadata": {
        "id": "9MPQoXMjrFmn"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove paddings because KDE does not work with paddings.\n",
        "\n",
        "X_unpadded = remove_paddings(X, padding_size)\n",
        "cf_embeddings_unpadded = remove_paddings(cf_embeddings, padding_size)"
      ],
      "metadata": {
        "id": "dh_BVpXMrtXu"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import gaussian_kde\n",
        "diffrences_from_abnormal = []\n",
        "diffrences_from_normal = []\n",
        "for dimention in range(cf_embeddings.shape[2]):\n",
        "\n",
        "\n",
        "  abnormal_data = X_unpadded[y_classes == 1][:,:,dimention]\n",
        "  normal_data = X_unpadded[y_classes == 0][:,:,dimention]\n",
        "  counterf_data = cf_embeddings_unpadded[:,:,dimention]\n",
        "\n",
        "  #get the kernel for every dimention of the trained\n",
        "  kernel = gaussian_kde(abnormal_data.T,bw_method=None)\n",
        "\n",
        "  #get all the log likelihoods\n",
        "  log_likelihood_abnormal = np.mean(kernel.logpdf(abnormal_data.T))\n",
        "  log_likelihood_normal = np.mean(kernel.logpdf(normal_data.T))\n",
        "  log_likelihood_counterfactual = np.mean(kernel.logpdf(counterf_data.T))\n",
        "\n",
        "  #get the diffrences from the counterfactuals\n",
        "  diff_from_abnormal = abs(log_likelihood_counterfactual-log_likelihood_abnormal)\n",
        "  diffrences_from_abnormal.append(diff_from_abnormal)\n",
        "\n",
        "  diff_from_normal = abs(log_likelihood_counterfactual-log_likelihood_normal)\n",
        "  diffrences_from_normal.append(diff_from_normal)\n",
        "\n"
      ],
      "metadata": {
        "id": "9Bb5nfXtOE4O"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(diffrences_from_normal)"
      ],
      "metadata": {
        "id": "9d4LPz8jhBve",
        "outputId": "20c72f52-9aa2-4a56-a5c5-d7d7397459fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[892.7991458090487, 507.48372717440674, 7212.293084950014, 3958.5777792982944, 2099.423277455748, 1611.05941927837, 165.18937917500892, 1822.2082178846972, 9589.997777367811, 152.54085558694976, 4013.7445440100078, 4718.30681153119, 633.267428552139, 503.42296635799187, 600.3581203729711, 503.651819148032, 355.0375695626642, 6437.292804080113, 1423.5699891917907, 5479.180789471258, 3398.933327073883, 2806.7413071480673, 5075.291598788244, 6253.685246278098, 802.6168025919274, 1783.8260108565705, 16.85973596370178, 531.4545656211949, 12818.045648106998, 2154.1262160324636, 382.64368370819966, 963.1352973523128, 378.94386723402806, 197.26409986287592, 1897.9236473696462, 633.5152151772783, 380.8124957713888, 958.7483504668301, 2668.741340940481, 647.8920008942112, 5174.720411037899, 2187.1670672468144, 5318.649274763037, 460.3466538873888, 1722.1228666513516, 467.49061963868866, 565.9474088245365, 12840.638502090847, 3336.3421812183788, 3581.144993835633, 4285.412114483446, 226.90951835406054, 5461.918328032382, 1055.500322758206, 239.24304327995407, 128.75418471419127, 577.5672233431387, 481.8172355358749, 513.6026159608792, 2689.6342436157124, 940.1606271101896, 355.3658643062711, 2147.688365509447, 7072.739880939961, 49.546977748148336, 2527.1994571290757, 12882.213413841335, 2008.7935165634935, 4913.904092917119, 523.2312089542885, 1430.4997577778447, 4112.191464180744, 5518.125650709329, 208.75177790134595, 3088.218844529587, 879.6930300419673, 1415.972848768122, 5077.775273467671, 66.69010963769955, 169.55908415108524, 931.1989715762343, 1013.5366014009494, 2224.0280703313097, 1378.02513627848, 124.10932943836391, 34.63719808071795, 5299.67160008617, 1137.0988027075414, 1308.5196461994979, 2615.497676219859, 1071.548221803553, 100.20054958089703, 2035.7488989819788, 6888.319258984912, 1950.1398922713424, 3737.765900075648, 1035.0203702449178, 1393.079904209262, 477.87844823199407, 5.785652955206189, 136.9692187194703, 656.323171129287, 103.23026913877509, 234.72253448944417, 1854.044807355764, 534.737229862458, 274.5476166866617, 1503.2831580342877, 405.72050139631006, 255.16148301164606, 687.0334947773085, 394.5473199461246, 18.92442330206609, 1772.5590651268217, 41.60780644695167, 531.6163443410961, 536.8513221292543, 1357.8657857211656, 93.77743167373694, 1240.281110856212, 611.7356690545494, 503.3176505951061, 5223.004581811463, 237.33164348514697, 549.7764728318855, 511.87895694529016, 291.20193806262074, 785.5382578826631, 1264.3185972868505, 132.2592099309734, 47.986453322581, 436.61344288393616, 31.76781204973311, 505.6513203683732, 1179.417083065029, 972.1282759994706, 132.17626958714928, 455.928427169227, 71.52205607211144, 112.40850421532598, 1439.1532594636801, 15.727567654972546, 107.01845481353713, 6.99801424219018]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(diffrences_from_abnormal)"
      ],
      "metadata": {
        "id": "bWvnGPiMi1Yt",
        "outputId": "2c75dc94-511d-467d-8edf-eed8a2896779",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[933.7437609518607, 550.0356467077538, 7255.690818955082, 3999.486812125629, 2138.9283884713145, 1654.8338847057285, 205.69768172354614, 1862.2773736106774, 9628.994373357355, 193.6650942326363, 4057.649927798447, 4758.0334041692695, 672.7045962495133, 543.3037580202272, 641.6607400740069, 539.8355213239021, 390.7068996600273, 6474.526901237176, 1464.2072304868768, 5517.516816821971, 3438.638718853822, 2848.29733521771, 5114.522623438901, 6294.656412630652, 842.9367151990947, 1822.137055622844, 56.223781822496335, 573.0719927973307, 12855.553071152304, 2194.7081023108376, 423.33744477418344, 1000.9707326848865, 415.685998760493, 237.30610143694793, 1936.3254118649068, 673.1364669225461, 417.7100147474101, 995.1943658933012, 2704.297305903219, 684.8462217809255, 5212.762508733597, 2227.442028815562, 5355.485777942547, 496.0628611529573, 1758.9217132253568, 508.17285213165883, 604.381199130286, 12880.752516447466, 3377.993924942566, 3617.8386152052894, 4324.343854746299, 267.5398222975398, 5500.0994613461025, 1093.7314585452223, 280.7729674529609, 166.43843230547114, 616.2698139802765, 522.2676979888332, 551.6001138278028, 2729.696451871538, 977.257004220513, 392.47445881133444, 2186.9030399472063, 7108.3587620109365, 86.30445205402215, 2563.315402586255, 12923.17533773023, 2045.8568112847545, 4952.785671411733, 562.116650949832, 1467.6746713180705, 4151.481535234712, 5554.50008198128, 245.23254050892143, 3125.4728689614376, 916.6063629800229, 1453.2046393165679, 5114.5835204599025, 108.24147215601104, 209.7735345160625, 970.2067331567711, 1052.8917364255021, 2261.31474952294, 1416.6147906522974, 163.40569258725935, 76.43000140093702, 5338.940548030773, 1173.0342481148116, 1346.4428483343497, 2657.0831114250022, 1111.3406998260125, 137.68609038221064, 2077.1329295844125, 6924.690370921669, 1985.9201411005938, 3778.289034919745, 1071.9958372026097, 1428.0590334847243, 517.5592194322276, 45.09924590780358, 178.39373816730978, 696.288436326741, 139.72701523358933, 271.64175902733336, 1892.3628936110006, 570.9480211115758, 311.88563670107146, 1539.8953671743209, 445.00441120856215, 292.994272148848, 727.5957269867814, 436.22995911624054, 61.0609584272366, 1812.8731201677383, 84.01105445951482, 573.3460430108111, 578.0763377777444, 1400.7546617172356, 135.93138744757573, 1281.071596354213, 653.960677739072, 545.4070524160678, 5263.81269598341, 280.12634960139883, 590.5679721750571, 553.6240950495949, 334.3214796703553, 828.9312868562521, 1306.7618730065035, 174.14589187246983, 89.2259884444549, 477.70342922999794, 73.46482498376952, 547.4991572012143, 1223.0076720807517, 1013.3163515340452, 175.890146750712, 498.8806160822867, 113.99713397894551, 154.49163023358932, 1481.6048847452996, 58.3719816329815, 149.8259145687065, 35.251347667169625]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(diffrences_from_normal))"
      ],
      "metadata": {
        "id": "vxNyE5DOkgIo",
        "outputId": "c1e872d5-e777-43e2-da44-c2a54e386240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1855.2384038996638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(diffrences_from_abnormal))"
      ],
      "metadata": {
        "id": "_YUPomtilE7p",
        "outputId": "1fd3bffe-1fbc-4bcd-b923-191d2cd91c8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1894.717835466105\n"
          ]
        }
      ]
    }
  ]
}