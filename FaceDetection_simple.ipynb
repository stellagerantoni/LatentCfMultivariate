{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stellagerantoni/LatentCfMultivariate/blob/main/FaceDetection_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/stellagerantoni/LatentCfMultivariate"
      ],
      "metadata": {
        "id": "1fwOXGEl_ine",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51791e40-4a4e-4d48-89d4-071dc05b20b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LatentCfMultivariate'...\n",
            "remote: Enumerating objects: 209, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 209 (delta 78), reused 36 (delta 36), pack-reused 105\u001b[K\n",
            "Receiving objects: 100% (209/209), 12.39 MiB | 10.64 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wildboar\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q stumpy\n",
        "!pip install -q fastdtw\n",
        "!pip install aeon"
      ],
      "metadata": {
        "id": "89L3kts7CCan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e967b6a0-16d3-4741-b4ad-447d99fcc088"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.1/169.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aeon\n",
            "  Downloading aeon-0.6.0-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (23.2.0)\n",
            "Collecting deprecated>=1.2.13 (from aeon)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numba>=0.55 in /usr/local/lib/python3.10/dist-packages (from aeon) (0.58.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (23.2)\n",
            "Requirement already satisfied: pandas<2.1.0,>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn<1.4.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.2.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.11.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->aeon) (1.14.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55->aeon) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.0,>=1.5.3->aeon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.0,>=1.5.3->aeon) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.0,>=1.0.0->aeon) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.0,>=1.0.0->aeon) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.1.0,>=1.5.3->aeon) (1.16.0)\n",
            "Installing collected packages: deprecated, aeon\n",
            "Successfully installed aeon-0.6.0 deprecated-1.2.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "from aeon.datasets import load_classification\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "%cd '/content/LatentCfMultivariate'\n",
        "from _guided import ModifiedLatentCF\n",
        "from help_functions import *\n",
        "from keras_models import *"
      ],
      "metadata": {
        "id": "Bdkpan5lCGRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7baa7ec-a32a-400e-85c4-7284c74d5043"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LatentCfMultivariate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n",
        "RANDOM_STATE = 39"
      ],
      "metadata": {
        "id": "GJE1AxFnE51S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ACTUALL CODE**\n",
        "datasets available : 'Heartbeat', 'SelfRegulationSCP1'"
      ],
      "metadata": {
        "id": "6vVfmpyuZyC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset):\n",
        "  X, y = load_classification(dataset)\n",
        "  if dataset == 'FaceDetection':\n",
        "    pos = '1'\n",
        "    neg = '0'\n",
        "\n",
        "\n",
        "  print(\" Shape of X = \", X.shape)\n",
        "  print(\" Shape of y = \", y.shape)\n",
        "  #print(\" Meta data = \", meta_data)\n",
        "  # Convert positive and negative labels to 1 and 0\n",
        "  pos_label, neg_label = 1, 0\n",
        "  if pos != pos_label:\n",
        "      y[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "  if neg != neg_label:\n",
        "      y[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "  y = y.astype(int)\n",
        "  print(f\"\\n X[:1] = \\n{X[:1]}\")\n",
        "  return X,y\n",
        ""
      ],
      "metadata": {
        "id": "Ya5WxsJ8TSgZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 39\n",
        "X, y = load_dataset('FaceDetection')\n",
        "X = X.transpose(0,2,1)\n",
        "print(f'shape of X = {X.shape}')\n",
        "print(f'shape of y = {y.shape}')\n",
        "#print(f'data imformation = {data_information}')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
        "print(f'shape of X train = {X_train.shape}')\n",
        "print(f'shape of y train = {y_train.shape}')"
      ],
      "metadata": {
        "id": "W4m9pwqyVY1b",
        "outputId": "a0f10cf5-09f9-495d-aa3c-46b876860eaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Shape of X =  (9414, 144, 62)\n",
            " Shape of y =  (9414,)\n",
            "\n",
            " X[:1] = \n",
            "[[[-0.07545  -0.336703 -0.278238 ... -0.411078 -1.016122 -1.161735]\n",
            "  [ 0.05608  -0.128013 -0.323847 ... -2.114348  0.208789 -0.509533]\n",
            "  [-0.824537 -0.746068 -0.482871 ... -0.929275 -1.007972 -0.292018]\n",
            "  ...\n",
            "  [-0.56758  -1.073942 -1.136367 ... -0.541122 -0.765445 -1.73308 ]\n",
            "  [-0.23404   0.104291  0.327425 ... -1.458801  0.318952  1.854007]\n",
            "  [-0.356189 -0.511199 -0.483072 ... -1.177502 -0.728301 -0.400074]]]\n",
            "shape of X = (9414, 62, 144)\n",
            "shape of y = (9414,)\n",
            "shape of X train = (7531, 62, 144)\n",
            "shape of y train = (7531,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upsample the minority class\n",
        "\n",
        "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "print(f'before: {class_counts}')\n",
        "X_train,y_train = upsample_minority_multivariate(X_train,y_train)\n",
        "X,y = upsample_minority_multivariate(X, y)\n",
        "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "print(f'after: {class_counts}')"
      ],
      "metadata": {
        "id": "Q2v7QdrHieA8",
        "outputId": "c86d738c-8fc1-4d7d-dc9b-e9dda1c8cb0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before: [3766 3765]\n",
            "after: [3766 3766]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing and Padding all our data\n",
        "#Padding needed for autoencoder\n",
        "\n",
        "n_training,n_timesteps, n_features= X_train.shape\n",
        "\n",
        "X, trained_scaler =  normalize_multivariate(data=X, n_timesteps=n_timesteps, n_features = n_features)\n",
        "X_train_processed, trained_scaler =  normalize_multivariate(data=X_train, n_timesteps=n_timesteps, n_features = n_features)\n",
        "X_test_processed, _ =  normalize_multivariate(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler, n_features = n_features)\n",
        "\n",
        "X, padding_size = conditional_pad_multivariate(X)\n",
        "X_train_processed_padded, padding_size = conditional_pad_multivariate(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad_multivariate(X_test_processed)\n",
        "\n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "print(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n",
        "\n",
        "#check the processing (0,1) min should be min 0 and max should be max 1\n",
        "print(f\"\\nmin value = {np.min(X_train)}, max value = {np.max(X_train)}\")\n",
        "print(f\"min value normalized = {np.min(X_train_processed)}, max value normalized= {np.max(X_train_processed)}\")\n",
        "\n",
        "#check that padding paddes the right dimention\n",
        "print(f\"\\nX_train.shape = {X_train.shape}\" )\n",
        "print(f\"X_train_processed_padded.shape = {X_train_processed_padded.shape}\")\n"
      ],
      "metadata": {
        "id": "00Q9QjKy7wEZ",
        "outputId": "e0dba2c4-5800-4ad5-f9c9-2aeb99d96cd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data pre-processed, original #timesteps=62, padded #timesteps=64.\n",
            "\n",
            "min value = -24.327769, max value = 24.326942\n",
            "min value normalized = 0.0, max value normalized= 1.0000000000000002\n",
            "\n",
            "X_train.shape = (7532, 62, 144)\n",
            "X_train_processed_padded.shape = (7532, 64, 144)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_validation, y_train, y_validation = train_test_split(X_train_processed_padded, y_train, test_size=0.2, random_state=RANDOM_STATE, stratify=y_train)"
      ],
      "metadata": {
        "id": "1mYFZmsvtB9q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the two forms of labels needed\n",
        "#-the y_classes (1,0,1,0,...)\n",
        "#-the y (one hot encoded)\n",
        "\n",
        "print(f'X_train = {X_train.shape}')\n",
        "print(f'X_validation = {X_validation.shape}')\n",
        "print(f'X_test = {X_test.shape}')\n",
        "\n",
        "y_classes = y\n",
        "y_train_classes = y_train\n",
        "y_validation_classes = y_validation\n",
        "y_test_classes = y_test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, len(np.unique(y)))\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_validation = to_categorical(y_validation, len(np.unique(y_validation)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))\n",
        "\n",
        "print(f'\\ny_train_classes = {y_train_classes.shape}, y_validation_classes = {y_validation_classes.shape}, y_test_classes = {y_test_classes.shape}')\n",
        "print(f'y_train = {y_train.shape}, y_validation = {y_validation.shape}, y_test= {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9b2F-vytxzU",
        "outputId": "6cede47f-2d74-45a0-826e-5330ad939639"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train = (6025, 64, 144)\n",
            "X_validation = (1507, 64, 144)\n",
            "X_test = (1883, 62, 144)\n",
            "\n",
            "y_train_classes = (6025,), y_validation_classes = (1507,), y_test_classes = (1883,)\n",
            "y_train = (6025, 2), y_validation = (1507, 2), y_test= (1883, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Classifier(\n",
        "    n_timesteps, n_features, n_conv_layers=1, add_dense_layer=True, n_output=2\n",
        "):\n",
        "    # https://keras.io/examples/timeseries/timeseries_classification_from_scratch/\n",
        "\n",
        "    input_shape = ( n_timesteps,n_features)\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape, dtype=\"float32\")\n",
        "\n",
        "    if add_dense_layer:\n",
        "        x = keras.layers.Dense(128, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(inputs)\n",
        "    else:\n",
        "        x = inputs\n",
        "\n",
        "    for i in range(n_conv_layers):\n",
        "        x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "        x = keras.layers.ReLU()(x)\n",
        "\n",
        "    x = keras.layers.MaxPooling1D(pool_size=2, padding=\"same\")(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "\n",
        "    if n_output >= 2:\n",
        "        outputs = keras.layers.Dense(n_output,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation=\"softmax\")(x)\n",
        "    else:\n",
        "        outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    classifier = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return classifier"
      ],
      "metadata": {
        "id": "WoMahiopQqxb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ## LatentCF++ models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "###############################################\n",
        "# ### 1dCNN classifier\n",
        "\n",
        "cnnClassifier = Classifier(\n",
        "    n_timesteps_padded, n_features, n_output=2, add_dense_layer = False\n",
        ")\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "cnnClassifier.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=15, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for LSTM-FCN classifier:\")\n",
        "classifier_history = cnnClassifier.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=150,\n",
        "    batch_size=12,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_validation, y_validation),\n",
        "    callbacks=[early_stopping_accuracy],\n",
        ")\n",
        "\n",
        "y_pred = cnnClassifier.predict(X_test_processed_padded)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "print(f\"LSTM-FCN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "    confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "    index=[\"True:1\", \"True:0\"],\n",
        "    columns=[\"Pred:1\", \"Pred:0\"],\n",
        ")\n",
        "print(confusion_matrix_df)\n"
      ],
      "metadata": {
        "id": "yNkKTXe6IIyF",
        "outputId": "4962dae8-5311-4297-d7f2-8112f07cdd16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training log for LSTM-FCN classifier:\n",
            "Epoch 1/150\n",
            "503/503 [==============================] - 8s 6ms/step - loss: 0.6606 - accuracy: 0.6363 - val_loss: 0.9228 - val_accuracy: 0.5063\n",
            "Epoch 2/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.5429 - accuracy: 0.7554 - val_loss: 1.3969 - val_accuracy: 0.5010\n",
            "Epoch 3/150\n",
            "503/503 [==============================] - 2s 5ms/step - loss: 0.4812 - accuracy: 0.7980 - val_loss: 0.9885 - val_accuracy: 0.5189\n",
            "Epoch 4/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.4344 - accuracy: 0.8305 - val_loss: 3.2467 - val_accuracy: 0.5003\n",
            "Epoch 5/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.3870 - accuracy: 0.8574 - val_loss: 2.4349 - val_accuracy: 0.5003\n",
            "Epoch 6/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.3454 - accuracy: 0.8830 - val_loss: 0.6247 - val_accuracy: 0.6768\n",
            "Epoch 7/150\n",
            "503/503 [==============================] - 2s 5ms/step - loss: 0.3106 - accuracy: 0.9064 - val_loss: 1.5699 - val_accuracy: 0.5030\n",
            "Epoch 8/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.2719 - accuracy: 0.9293 - val_loss: 1.4975 - val_accuracy: 0.5554\n",
            "Epoch 9/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.2495 - accuracy: 0.9419 - val_loss: 3.0889 - val_accuracy: 0.5036\n",
            "Epoch 10/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.2259 - accuracy: 0.9552 - val_loss: 0.6065 - val_accuracy: 0.7903\n",
            "Epoch 11/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.2017 - accuracy: 0.9660 - val_loss: 2.3472 - val_accuracy: 0.5023\n",
            "Epoch 12/150\n",
            "503/503 [==============================] - 2s 5ms/step - loss: 0.2304 - accuracy: 0.9517 - val_loss: 0.9975 - val_accuracy: 0.6370\n",
            "Epoch 13/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.1721 - accuracy: 0.9771 - val_loss: 0.5233 - val_accuracy: 0.8009\n",
            "Epoch 14/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.1484 - accuracy: 0.9837 - val_loss: 0.5923 - val_accuracy: 0.7704\n",
            "Epoch 15/150\n",
            "503/503 [==============================] - 2s 5ms/step - loss: 0.1469 - accuracy: 0.9885 - val_loss: 0.5311 - val_accuracy: 0.8129\n",
            "Epoch 16/150\n",
            "503/503 [==============================] - 2s 5ms/step - loss: 0.1448 - accuracy: 0.9849 - val_loss: 2.0361 - val_accuracy: 0.5275\n",
            "Epoch 17/150\n",
            "503/503 [==============================] - 2s 5ms/step - loss: 0.1257 - accuracy: 0.9935 - val_loss: 0.5708 - val_accuracy: 0.7631\n",
            "Epoch 18/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.1255 - accuracy: 0.9924 - val_loss: 0.6225 - val_accuracy: 0.7870\n",
            "Epoch 19/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.1114 - accuracy: 0.9939 - val_loss: 2.3684 - val_accuracy: 0.5143\n",
            "Epoch 20/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.1124 - accuracy: 0.9939 - val_loss: 0.7631 - val_accuracy: 0.7040\n",
            "Epoch 21/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.1044 - accuracy: 0.9954 - val_loss: 1.6822 - val_accuracy: 0.5574\n",
            "Epoch 22/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0978 - accuracy: 0.9963 - val_loss: 0.6312 - val_accuracy: 0.7704\n",
            "Epoch 23/150\n",
            "503/503 [==============================] - 4s 7ms/step - loss: 0.0924 - accuracy: 0.9960 - val_loss: 3.0019 - val_accuracy: 0.5017\n",
            "Epoch 24/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.1064 - accuracy: 0.9912 - val_loss: 0.6838 - val_accuracy: 0.7439\n",
            "Epoch 25/150\n",
            "503/503 [==============================] - 2s 5ms/step - loss: 0.0924 - accuracy: 0.9955 - val_loss: 0.7206 - val_accuracy: 0.7213\n",
            "Epoch 26/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0754 - accuracy: 0.9980 - val_loss: 0.5402 - val_accuracy: 0.8222\n",
            "Epoch 27/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0885 - accuracy: 0.9952 - val_loss: 0.8711 - val_accuracy: 0.6775\n",
            "Epoch 28/150\n",
            "503/503 [==============================] - 3s 7ms/step - loss: 0.0763 - accuracy: 0.9978 - val_loss: 1.6287 - val_accuracy: 0.5528\n",
            "Epoch 29/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0635 - accuracy: 0.9995 - val_loss: 0.4866 - val_accuracy: 0.8394\n",
            "Epoch 30/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.0651 - accuracy: 0.9978 - val_loss: 0.5126 - val_accuracy: 0.8222\n",
            "Epoch 31/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0823 - accuracy: 0.9930 - val_loss: 2.7199 - val_accuracy: 0.5103\n",
            "Epoch 32/150\n",
            "503/503 [==============================] - 3s 7ms/step - loss: 0.1060 - accuracy: 0.9877 - val_loss: 0.8926 - val_accuracy: 0.6821\n",
            "Epoch 33/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.0625 - accuracy: 0.9990 - val_loss: 0.7408 - val_accuracy: 0.7910\n",
            "Epoch 34/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.8248\n",
            "Epoch 35/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0496 - accuracy: 0.9998 - val_loss: 0.7484 - val_accuracy: 0.7551\n",
            "Epoch 36/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0845 - accuracy: 0.9912 - val_loss: 0.6546 - val_accuracy: 0.7465\n",
            "Epoch 37/150\n",
            "503/503 [==============================] - 4s 8ms/step - loss: 0.0797 - accuracy: 0.9944 - val_loss: 1.9347 - val_accuracy: 0.5766\n",
            "Epoch 38/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0493 - accuracy: 0.9998 - val_loss: 0.5218 - val_accuracy: 0.8527\n",
            "Epoch 39/150\n",
            "503/503 [==============================] - 2s 5ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.6534 - val_accuracy: 0.8049\n",
            "Epoch 40/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0987 - accuracy: 0.9802 - val_loss: 1.9066 - val_accuracy: 0.5163\n",
            "Epoch 41/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0735 - accuracy: 0.9949 - val_loss: 0.9385 - val_accuracy: 0.7379\n",
            "Epoch 42/150\n",
            "503/503 [==============================] - 5s 9ms/step - loss: 0.0664 - accuracy: 0.9957 - val_loss: 0.6179 - val_accuracy: 0.8228\n",
            "Epoch 43/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0428 - accuracy: 0.9998 - val_loss: 0.5485 - val_accuracy: 0.8487\n",
            "Epoch 44/150\n",
            "503/503 [==============================] - 2s 5ms/step - loss: 0.0424 - accuracy: 0.9992 - val_loss: 0.6849 - val_accuracy: 0.7804\n",
            "Epoch 45/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0419 - accuracy: 0.9998 - val_loss: 0.5385 - val_accuracy: 0.8348\n",
            "Epoch 46/150\n",
            "503/503 [==============================] - 3s 7ms/step - loss: 0.0722 - accuracy: 0.9904 - val_loss: 0.7268 - val_accuracy: 0.7273\n",
            "Epoch 47/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0500 - accuracy: 0.9992 - val_loss: 0.4823 - val_accuracy: 0.8640\n",
            "Epoch 48/150\n",
            "503/503 [==============================] - 2s 5ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.8613\n",
            "Epoch 49/150\n",
            "503/503 [==============================] - 2s 5ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 2.9318 - val_accuracy: 0.5169\n",
            "Epoch 50/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0816 - accuracy: 0.9836 - val_loss: 3.2060 - val_accuracy: 0.5030\n",
            "Epoch 51/150\n",
            "503/503 [==============================] - 4s 7ms/step - loss: 0.1428 - accuracy: 0.9650 - val_loss: 4.1526 - val_accuracy: 0.5103\n",
            "Epoch 52/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0475 - accuracy: 0.9993 - val_loss: 0.8513 - val_accuracy: 0.8089\n",
            "Epoch 53/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8713\n",
            "Epoch 54/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0416 - accuracy: 0.9993 - val_loss: 4.4380 - val_accuracy: 0.5043\n",
            "Epoch 55/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.0364 - accuracy: 0.9995 - val_loss: 0.6227 - val_accuracy: 0.7903\n",
            "Epoch 56/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.0372 - accuracy: 0.9993 - val_loss: 0.6855 - val_accuracy: 0.7697\n",
            "Epoch 57/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.1421 - accuracy: 0.9625 - val_loss: 0.7314 - val_accuracy: 0.7664\n",
            "Epoch 58/150\n",
            "503/503 [==============================] - 2s 5ms/step - loss: 0.0457 - accuracy: 0.9997 - val_loss: 0.5475 - val_accuracy: 0.8607\n",
            "Epoch 59/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0488 - accuracy: 0.9967 - val_loss: 0.5891 - val_accuracy: 0.8620\n",
            "Epoch 60/150\n",
            "503/503 [==============================] - 3s 7ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.8733\n",
            "Epoch 61/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0365 - accuracy: 0.9983 - val_loss: 1.4752 - val_accuracy: 0.6211\n",
            "Epoch 62/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0807 - accuracy: 0.9877 - val_loss: 1.5537 - val_accuracy: 0.6065\n",
            "Epoch 63/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0408 - accuracy: 0.9997 - val_loss: 0.5389 - val_accuracy: 0.8666\n",
            "Epoch 64/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.8626\n",
            "Epoch 65/150\n",
            "503/503 [==============================] - 4s 7ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.8587\n",
            "Epoch 66/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0471 - accuracy: 0.9970 - val_loss: 5.0513 - val_accuracy: 0.4997\n",
            "Epoch 67/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0549 - accuracy: 0.9942 - val_loss: 0.5829 - val_accuracy: 0.8354\n",
            "Epoch 68/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0435 - accuracy: 0.9977 - val_loss: 1.4923 - val_accuracy: 0.8288\n",
            "Epoch 69/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.0360 - accuracy: 0.9997 - val_loss: 0.5379 - val_accuracy: 0.8739\n",
            "Epoch 70/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.5268 - val_accuracy: 0.8500\n",
            "Epoch 71/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0722 - accuracy: 0.9861 - val_loss: 1.5655 - val_accuracy: 0.5713\n",
            "Epoch 72/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0498 - accuracy: 0.9968 - val_loss: 0.6631 - val_accuracy: 0.8407\n",
            "Epoch 73/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.5728 - val_accuracy: 0.8587\n",
            "Epoch 74/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.6375 - val_accuracy: 0.8281\n",
            "Epoch 75/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.0251 - accuracy: 0.9998 - val_loss: 0.6479 - val_accuracy: 0.8328\n",
            "Epoch 76/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.1030 - accuracy: 0.9754 - val_loss: 0.6370 - val_accuracy: 0.8202\n",
            "Epoch 77/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0405 - accuracy: 0.9988 - val_loss: 0.5769 - val_accuracy: 0.8626\n",
            "Epoch 78/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.5160 - val_accuracy: 0.8560\n",
            "Epoch 79/150\n",
            "503/503 [==============================] - 4s 7ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.5391 - val_accuracy: 0.8607\n",
            "Epoch 80/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0236 - accuracy: 0.9998 - val_loss: 0.8612 - val_accuracy: 0.7346\n",
            "Epoch 81/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0993 - accuracy: 0.9774 - val_loss: 1.6322 - val_accuracy: 0.5919\n",
            "Epoch 82/150\n",
            "503/503 [==============================] - 3s 5ms/step - loss: 0.0368 - accuracy: 0.9998 - val_loss: 1.2001 - val_accuracy: 0.6974\n",
            "Epoch 83/150\n",
            "503/503 [==============================] - 3s 6ms/step - loss: 0.0381 - accuracy: 0.9985 - val_loss: 0.5655 - val_accuracy: 0.8673\n",
            "Epoch 84/150\n",
            "503/503 [==============================] - 4s 9ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.6112 - val_accuracy: 0.8288\n",
            "59/59 [==============================] - 0s 3ms/step\n",
            "LSTM-FCN classifier trained, with validation accuracy 0.7339980280272826.\n",
            "        Pred:1  Pred:0\n",
            "True:1     580     362\n",
            "True:0     139     802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder( n_timesteps_padded,n_features,32)\n",
        "optimizer = keras.optimizers.Adam(lr=0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, restore_best_weights=True)\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    batch_size=12,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    validation_data=(X_validation, X_validation),\n",
        "    callbacks=[early_stopping])\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history['val_loss'])\n",
        "print(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")\n"
      ],
      "metadata": {
        "id": "E6IxH8BLEKFG",
        "outputId": "d44a7a3c-492a-4c76-9bd4-5c8a2c0cd6ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 64, 144)\n",
            "(None, 64, 32)\n",
            "(None, 32, 32)\n",
            "(None, 32, 16)\n",
            "(None, 16, 16)\n",
            "(None, 16, 16)\n",
            "(None, 32, 16)\n",
            "(None, 32, 32)\n",
            "(None, 64, 32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 64, 144)\n",
            "Training log for 1dCNN autoencoder:\n",
            "Epoch 1/50\n",
            "503/503 - 7s - loss: 0.0078 - val_loss: 7.3700e-04 - 7s/epoch - 14ms/step\n",
            "Epoch 2/50\n",
            "503/503 - 5s - loss: 7.8466e-04 - val_loss: 7.1343e-04 - 5s/epoch - 10ms/step\n",
            "Epoch 3/50\n",
            "503/503 - 4s - loss: 7.7242e-04 - val_loss: 7.0874e-04 - 4s/epoch - 7ms/step\n",
            "Epoch 4/50\n",
            "503/503 - 3s - loss: 7.6786e-04 - val_loss: 7.1045e-04 - 3s/epoch - 6ms/step\n",
            "Epoch 5/50\n",
            "503/503 - 3s - loss: 7.6305e-04 - val_loss: 7.1024e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 6/50\n",
            "503/503 - 3s - loss: 7.5890e-04 - val_loss: 7.0490e-04 - 3s/epoch - 6ms/step\n",
            "1dCNN autoencoder trained, with validation loss: 0.0007048972765915096.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gettting the Global weights, needed for counterfactuals\n",
        "\n",
        "from _guided import get_global_weights\n",
        "from help_functions import evaluate\n",
        "pos_label = 1\n",
        "neg_label = 0\n",
        "\n",
        "step_weights = get_global_weights(\n",
        "        X,\n",
        "        y_classes,\n",
        "        cnnClassifier,\n",
        "        n_timesteps= n_timesteps,\n",
        "        n_features=n_features,\n",
        "        random_state=RANDOM_STATE,\n",
        ")\n"
      ],
      "metadata": {
        "id": "hysd9dxSsx9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6b29f6-701c-4c3b-af82-3ff338f0aadd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 2s 5ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n",
            "295/295 [==============================] - 1s 3ms/step\n",
            "295/295 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step_weights"
      ],
      "metadata": {
        "id": "3WcwnNgc3RdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5,tolerance=1e-6, max_iter=500, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),autoencoder = autoencoder,\n",
        "    pred_margin_weight=0.7, step_weights = step_weights, random_state= RANDOM_STATE)\n",
        "cf_model.fit(cnnClassifier)\n",
        "\n",
        "y_neg = y_classes[y_classes == 0]\n",
        "X_neg = X[y_classes == 0]\n",
        "\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses, weights = cf_model.transform(X_neg, y_neg) #self, x, pred_label\n",
        "cf_pred_labels = cnnClassifier.predict(cf_embeddings)[:,1]# predicted probabilities of CFs\n",
        "for idx in range(cf_pred_labels.shape[0]):\n",
        "  if cf_pred_labels[idx] > 0.5:\n",
        "    cf_pred_labels[idx] = 1\n",
        "  else:\n",
        "    cf_pred_labels[idx] = 0\n",
        "\n",
        "print(f'Transformation_finished with validity_score = {validity_score(y_neg,cf_pred_labels)}')"
      ],
      "metadata": {
        "id": "f-Xy39aj8q9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating proximity\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "total = 0\n",
        "probability = 0.5\n",
        "for idx in range(cf_embeddings.shape[0]):\n",
        "    counterfactual = cf_embeddings[idx,np.newaxis]\n",
        "    prediction = cnnClassifier.predict(counterfactual)[:, 1]\n",
        "    dist = (prediction - probability)\n",
        "    total +=dist\n",
        "mean_mse = total /cf_embeddings.shape[0]\n"
      ],
      "metadata": {
        "id": "ZkPSSHScmi2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The Mean MSE of the data is: {mean_mse} \")"
      ],
      "metadata": {
        "id": "6FXZX1A-5Er1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating proximity\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "total = 0\n",
        "probability = 0.5\n",
        "for idx in range(cf_embeddings.shape[0]):\n",
        "    counterfactual = cf_embeddings[idx,np.newaxis]\n",
        "    prediction = cnnClassifier.predict(counterfactual)[:, 1]\n",
        "    dist = abs(prediction - probability)\n",
        "    total +=dist\n",
        "mean_mse = total /cf_embeddings.shape[0]\n"
      ],
      "metadata": {
        "id": "AcUwDKnZmj6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The Absolute Mean MSE of the data is: {mean_mse} \")"
      ],
      "metadata": {
        "id": "1x5s2_8H5F3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_paddings(cf_samples, padding_size):\n",
        "    if padding_size != 0:\n",
        "        # use np.squeeze() to cut the last time-series dimension, for evaluation\n",
        "        cf_samples = np.squeeze(cf_samples[:, :-padding_size, :])\n",
        "    else:\n",
        "        cf_samples = np.squeeze(cf_samples)\n",
        "    return cf_samples"
      ],
      "metadata": {
        "id": "74VVIGnzdNG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = remove_paddings(X, padding_size)\n",
        "cf_embeddings = remove_paddings(cf_embeddings, padding_size)\n"
      ],
      "metadata": {
        "id": "D4u5L_H5Zrx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Proximity\n",
        "def euclidean_distance(X, cf_samples):\n",
        "    paired_distances = np.linalg.norm(X - cf_samples, axis=1)\n",
        "    return np.mean(paired_distances)\n",
        "euclidean_distance(X_neg, cf_embeddings)"
      ],
      "metadata": {
        "id": "50Hed3JXrm1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_paddings(cf_samples, padding_size):\n",
        "    if padding_size != 0:\n",
        "        # use np.squeeze() to cut the last time-series dimension, for evaluation\n",
        "        cf_samples = np.squeeze(cf_samples[:, :-padding_size, :])\n",
        "    else:\n",
        "        cf_samples = np.squeeze(cf_samples)\n",
        "    return cf_samples"
      ],
      "metadata": {
        "id": "9MPQoXMjrFmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove paddings because KDE does not work with paddings.\n",
        "\n",
        "X_unpadded = remove_paddings(X, padding_size)\n",
        "cf_embeddings_unpadded = remove_paddings(cf_embeddings, padding_size)"
      ],
      "metadata": {
        "id": "dh_BVpXMrtXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import gaussian_kde\n",
        "diffrences_from_abnormal = []\n",
        "diffrences_from_normal = []\n",
        "for dimention in range(cf_embeddings.shape[2]):\n",
        "\n",
        "\n",
        "  abnormal_data = X[y_classes == 1][:,:,dimention]\n",
        "  normal_data = X[y_classes == 0][:,:,dimention]\n",
        "  counterf_data = cf_embeddings[:,:,dimention]\n",
        "\n",
        "  #get the kernel for every dimention of the trained\n",
        "  kernel = gaussian_kde(abnormal_data.T,bw_method=None)\n",
        "\n",
        "  #get all the log likelihoods\n",
        "  log_likelihood_abnormal = np.mean(kernel.logpdf(abnormal_data.T))\n",
        "  log_likelihood_normal = np.mean(kernel.logpdf(normal_data.T))\n",
        "  log_likelihood_counterfactual = np.mean(kernel.logpdf(counterf_data.T))\n",
        "\n",
        "  #get the diffrences from the counterfactuals\n",
        "  diff_from_abnormal = abs(log_likelihood_counterfactual-log_likelihood_abnormal)\n",
        "  diffrences_from_abnormal.append(diff_from_abnormal)\n",
        "\n",
        "  diff_from_normal = abs(log_likelihood_counterfactual-log_likelihood_normal)\n",
        "  diffrences_from_normal.append(diff_from_normal)\n",
        "\n"
      ],
      "metadata": {
        "id": "9Bb5nfXtOE4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(diffrences_from_normal)"
      ],
      "metadata": {
        "id": "9d4LPz8jhBve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(diffrences_from_abnormal)"
      ],
      "metadata": {
        "id": "bWvnGPiMi1Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(diffrences_from_normal))"
      ],
      "metadata": {
        "id": "vxNyE5DOkgIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(diffrences_from_abnormal))"
      ],
      "metadata": {
        "id": "_YUPomtilE7p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}