{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPEA/oAkvajXLsREtyNVRqC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stellagerantoni/LatentCfMultivariate/blob/main/FingerMovements_KDE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/stellagerantoni/LatentCfMultivariate"
      ],
      "metadata": {
        "id": "1fwOXGEl_ine",
        "outputId": "fba78fea-2b71-4055-899f-4b1e5d839304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LatentCfMultivariate'...\n",
            "remote: Enumerating objects: 189, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 189 (delta 65), reused 36 (delta 36), pack-reused 105\u001b[K\n",
            "Receiving objects: 100% (189/189), 12.36 MiB | 7.96 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wildboar\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q stumpy\n",
        "!pip install -q fastdtw"
      ],
      "metadata": {
        "id": "89L3kts7CCan",
        "outputId": "d917fd54-de7a-47c5-b0c5-005bb9b565b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.1/169.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aeon"
      ],
      "metadata": {
        "id": "qZh6v946Bhq8",
        "outputId": "022af656-a240-4683-94cc-cf074432e8b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aeon\n",
            "  Downloading aeon-0.6.0-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (23.2.0)\n",
            "Collecting deprecated>=1.2.13 (from aeon)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numba>=0.55 in /usr/local/lib/python3.10/dist-packages (from aeon) (0.58.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (23.2)\n",
            "Requirement already satisfied: pandas<2.1.0,>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn<1.4.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.2.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.11.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->aeon) (1.14.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55->aeon) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.0,>=1.5.3->aeon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.0,>=1.5.3->aeon) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.0,>=1.0.0->aeon) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.0,>=1.0.0->aeon) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.1.0,>=1.5.3->aeon) (1.16.0)\n",
            "Installing collected packages: deprecated, aeon\n",
            "Successfully installed aeon-0.6.0 deprecated-1.2.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "from aeon.datasets import load_classification\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "%cd '/content/LatentCfMultivariate'\n",
        "from _guided import ModifiedLatentCF\n",
        "from help_functions import *\n",
        "from keras_models import *"
      ],
      "metadata": {
        "id": "Bdkpan5lCGRH",
        "outputId": "1b7e3fbd-be50-4b20-9f1d-7c9b21f2cf6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LatentCfMultivariate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n",
        "RANDOM_STATE = 39"
      ],
      "metadata": {
        "id": "GJE1AxFnE51S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset):\n",
        "  X, y = load_classification(dataset)\n",
        "  if dataset == 'FingerMovements':\n",
        "    pos = 'left'\n",
        "    neg = 'right'\n",
        "\n",
        "\n",
        "  print(\" Shape of X = \", X.shape)\n",
        "  print(\" Shape of y = \", y.shape)\n",
        "  #print(\" Meta data = \", meta_data)\n",
        "  # Convert positive and negative labels to 1 and 0\n",
        "  pos_label, neg_label = 1, 0\n",
        "  if pos != pos_label:\n",
        "      y[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "  if neg != neg_label:\n",
        "      y[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "  y = y.astype(int)\n",
        "  print(f\"\\n X[:1] = \\n{X[:1]}\")\n",
        "  return X,y,pos_label, neg_label"
      ],
      "metadata": {
        "id": "1gOYu412Vx7m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ACTUALL CODE**\n"
      ],
      "metadata": {
        "id": "6vVfmpyuZyC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 39\n",
        "X,y,pos_label,neg_label = load_dataset('FingerMovements')\n",
        "X = X.transpose(0,2,1)\n",
        "print(f'shape of X = {X.shape}')\n",
        "print(f'shape of y = {y.shape}')\n",
        "#print(f'data imformation = {data_information}')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
        "print(f'shape of X train = {X_train.shape}')\n",
        "print(f'shape of y train = {y_train.shape}')"
      ],
      "metadata": {
        "id": "W4m9pwqyVY1b",
        "outputId": "dce25de2-cd5e-4a6d-f897-1ef93f3d3915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Shape of X =  (416, 28, 50)\n",
            " Shape of y =  (416,)\n",
            "\n",
            " X[:1] = \n",
            "[[[41.8 44.8 47.1 ... 69.8 72.6 76.1]\n",
            "  [55.2 53.8 59.9 ... 17.5 28.  12.1]\n",
            "  [-8.6 -3.6 14.4 ... 23.3 35.9 23.2]\n",
            "  ...\n",
            "  [16.9 24.5 24.5 ... 51.9 59.6 57.3]\n",
            "  [42.2 35.  41.7 ... 51.5 58.5 46.9]\n",
            "  [13.  26.6 52.5 ... -3.5 -3.2 -2.6]]]\n",
            "shape of X = (416, 50, 28)\n",
            "shape of y = (416,)\n",
            "shape of X train = (332, 50, 28)\n",
            "shape of y train = (332,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upsample the minority class\n",
        "\n",
        "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "print(f'before: {class_counts}')\n",
        "X_train,y_train = upsample_minority_multivariate(X_train,y_train)\n",
        "X,y = upsample_minority_multivariate(X, y)\n",
        "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "print(f'after: {class_counts}')"
      ],
      "metadata": {
        "id": "Q2v7QdrHieA8",
        "outputId": "a14206f9-9baa-411f-de43-d553d2d6c31b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before: [166 166]\n",
            "after: [166 166]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing and Padding all our data\n",
        "#Padding needed for autoencoder\n",
        "\n",
        "n_training,n_timesteps, n_features= X_train.shape\n",
        "\n",
        "X, trained_scaler =  normalize_multivariate(data=X, n_timesteps=n_timesteps, n_features = n_features)\n",
        "X_train_processed, trained_scaler =  normalize_multivariate(data=X_train, n_timesteps=n_timesteps, n_features = n_features)\n",
        "X_test_processed, _ =  normalize_multivariate(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler, n_features = n_features)\n",
        "\n",
        "X, padding_size = conditional_pad_multivariate(X)\n",
        "X_train_processed_padded, padding_size = conditional_pad_multivariate(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad_multivariate(X_test_processed)\n",
        "\n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "print(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n",
        "\n",
        "#check the processing (0,1) min should be min 0 and max should be max 1\n",
        "print(f\"\\nmin value = {np.min(X_train)}, max value = {np.max(X_train)}\")\n",
        "print(f\"min value normalized = {np.min(X_train_processed)}, max value normalized= {np.max(X_train_processed)}\")\n",
        "\n",
        "#check that padding paddes the right dimention\n",
        "print(f\"\\nX_train.shape = {X_train.shape}\" )\n",
        "print(f\"X_train_processed_padded.shape = {X_train_processed_padded.shape}\")\n"
      ],
      "metadata": {
        "id": "00Q9QjKy7wEZ",
        "outputId": "3ff851aa-e47a-4572-a08c-202243cc8272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data pre-processed, original #timesteps=50, padded #timesteps=52.\n",
            "\n",
            "min value = -132.1, max value = 205.1\n",
            "min value normalized = 0.0, max value normalized= 1.0\n",
            "\n",
            "X_train.shape = (332, 50, 28)\n",
            "X_train_processed_padded.shape = (332, 52, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_validation, y_train, y_validation = train_test_split(X_train_processed_padded, y_train, test_size=0.2, random_state=RANDOM_STATE, stratify=y_train)"
      ],
      "metadata": {
        "id": "1mYFZmsvtB9q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the two forms of labels needed\n",
        "#-the y_classes (1,0,1,0,...)\n",
        "#-the y (one hot encoded)\n",
        "\n",
        "print(f'X_train = {X_train.shape}')\n",
        "print(f'X_validation = {X_validation.shape}')\n",
        "print(f'X_test = {X_test.shape}')\n",
        "\n",
        "y_classes = y\n",
        "y_train_classes = y_train\n",
        "y_validation_classes = y_validation\n",
        "y_test_classes = y_test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, len(np.unique(y)))\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_validation = to_categorical(y_validation, len(np.unique(y_validation)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))\n",
        "\n",
        "print(f'\\ny_train_classes = {y_train_classes.shape}, y_validation_classes = {y_validation_classes.shape}, y_test_classes = {y_test_classes.shape}')\n",
        "print(f'y_train = {y_train.shape}, y_validation = {y_validation.shape}, y_test= {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9b2F-vytxzU",
        "outputId": "02cecc3b-938f-40a5-b9b1-3a1645219f76"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train = (265, 52, 28)\n",
            "X_validation = (67, 52, 28)\n",
            "X_test = (84, 50, 28)\n",
            "\n",
            "y_train_classes = (265,), y_validation_classes = (67,), y_test_classes = (84,)\n",
            "y_train = (265, 2), y_validation = (67, 2), y_test= (84, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ## LatentCF++ models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "###############################################\n",
        "# ### 1dCNN classifier\n",
        "\n",
        "cnnClassifier = Classifier(\n",
        "    n_timesteps_padded, n_features, n_output=2, add_dense_layer = False\n",
        ")\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "cnnClassifier.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=15, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for LSTM-FCN classifier:\")\n",
        "classifier_history = cnnClassifier.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=150,\n",
        "    batch_size=12,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_validation, y_validation),\n",
        "    callbacks=[early_stopping_accuracy],\n",
        ")\n",
        "\n",
        "y_pred = cnnClassifier.predict(X_test_processed_padded)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "print(f\"LSTM-FCN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "    confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "    index=[\"True:1\", \"True:0\"],\n",
        "    columns=[\"Pred:1\", \"Pred:0\"],\n",
        ")\n",
        "print(confusion_matrix_df)\n"
      ],
      "metadata": {
        "id": "yNkKTXe6IIyF",
        "outputId": "8419e4fe-a0cb-45e6-a4b0-75ada6b3b395",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training log for LSTM-FCN classifier:\n",
            "Epoch 1/150\n",
            "23/23 [==============================] - 4s 42ms/step - loss: 0.8307 - accuracy: 0.5132 - val_loss: 0.7577 - val_accuracy: 0.4925\n",
            "Epoch 2/150\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6913 - accuracy: 0.6226 - val_loss: 0.7282 - val_accuracy: 0.5224\n",
            "Epoch 3/150\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6332 - accuracy: 0.7132 - val_loss: 0.7123 - val_accuracy: 0.6567\n",
            "Epoch 4/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7008 - accuracy: 0.6189 - val_loss: 0.7063 - val_accuracy: 0.6418\n",
            "Epoch 5/150\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5797 - accuracy: 0.7585 - val_loss: 0.7009 - val_accuracy: 0.6567\n",
            "Epoch 6/150\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5776 - accuracy: 0.7736 - val_loss: 0.7315 - val_accuracy: 0.4925\n",
            "Epoch 7/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5878 - accuracy: 0.7321 - val_loss: 0.7397 - val_accuracy: 0.5075\n",
            "Epoch 8/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5362 - accuracy: 0.7811 - val_loss: 0.7104 - val_accuracy: 0.5224\n",
            "Epoch 9/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.4929 - accuracy: 0.8264 - val_loss: 0.7111 - val_accuracy: 0.5821\n",
            "Epoch 10/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.4731 - accuracy: 0.8717 - val_loss: 0.6920 - val_accuracy: 0.5821\n",
            "Epoch 11/150\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.4994 - accuracy: 0.8038 - val_loss: 0.6319 - val_accuracy: 0.8209\n",
            "Epoch 12/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4903 - accuracy: 0.8189 - val_loss: 0.6336 - val_accuracy: 0.7164\n",
            "Epoch 13/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.8717 - val_loss: 0.6221 - val_accuracy: 0.6567\n",
            "Epoch 14/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8906 - val_loss: 0.7378 - val_accuracy: 0.5672\n",
            "Epoch 15/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.8000 - val_loss: 0.6105 - val_accuracy: 0.7015\n",
            "Epoch 16/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8943 - val_loss: 0.5868 - val_accuracy: 0.6567\n",
            "Epoch 17/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8981 - val_loss: 0.5746 - val_accuracy: 0.7761\n",
            "Epoch 18/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8830 - val_loss: 0.6514 - val_accuracy: 0.6119\n",
            "Epoch 19/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8717 - val_loss: 0.5857 - val_accuracy: 0.7463\n",
            "Epoch 20/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3639 - accuracy: 0.8868 - val_loss: 0.5641 - val_accuracy: 0.7761\n",
            "Epoch 21/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.9019 - val_loss: 0.5201 - val_accuracy: 0.7612\n",
            "Epoch 22/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2989 - accuracy: 0.9321 - val_loss: 0.7337 - val_accuracy: 0.6119\n",
            "Epoch 23/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3010 - accuracy: 0.9321 - val_loss: 0.4953 - val_accuracy: 0.8060\n",
            "Epoch 24/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2984 - accuracy: 0.9245 - val_loss: 0.4660 - val_accuracy: 0.8657\n",
            "Epoch 25/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2896 - accuracy: 0.9245 - val_loss: 1.5668 - val_accuracy: 0.5075\n",
            "Epoch 26/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3239 - accuracy: 0.8943 - val_loss: 0.4682 - val_accuracy: 0.8507\n",
            "Epoch 27/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2924 - accuracy: 0.9396 - val_loss: 1.2695 - val_accuracy: 0.5373\n",
            "Epoch 28/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8491 - val_loss: 0.5414 - val_accuracy: 0.8209\n",
            "Epoch 29/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8830 - val_loss: 0.4692 - val_accuracy: 0.8507\n",
            "Epoch 30/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2810 - accuracy: 0.9208 - val_loss: 0.5567 - val_accuracy: 0.7761\n",
            "Epoch 31/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2764 - accuracy: 0.9472 - val_loss: 0.4888 - val_accuracy: 0.7910\n",
            "Epoch 32/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2381 - accuracy: 0.9736 - val_loss: 0.4446 - val_accuracy: 0.8209\n",
            "Epoch 33/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.9170 - val_loss: 0.5471 - val_accuracy: 0.7015\n",
            "Epoch 34/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9660 - val_loss: 1.6652 - val_accuracy: 0.5224\n",
            "Epoch 35/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2545 - accuracy: 0.9623 - val_loss: 0.9761 - val_accuracy: 0.5970\n",
            "Epoch 36/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2357 - accuracy: 0.9547 - val_loss: 0.5188 - val_accuracy: 0.7910\n",
            "Epoch 37/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2169 - accuracy: 0.9811 - val_loss: 0.4607 - val_accuracy: 0.8358\n",
            "Epoch 38/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2486 - accuracy: 0.9472 - val_loss: 0.5106 - val_accuracy: 0.7761\n",
            "Epoch 39/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1965 - accuracy: 0.9849 - val_loss: 1.3675 - val_accuracy: 0.6119\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "LSTM-FCN classifier trained, with validation accuracy 0.4523809523809524.\n",
            "        Pred:1  Pred:0\n",
            "True:1      19      23\n",
            "True:0      23      19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder( n_timesteps_padded,n_features,32)\n",
        "optimizer = keras.optimizers.Adam(lr=0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, restore_best_weights=True)\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    batch_size=12,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    validation_data=(X_validation, X_validation),\n",
        "    callbacks=[early_stopping])\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history['val_loss'])\n",
        "print(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")\n"
      ],
      "metadata": {
        "id": "E6IxH8BLEKFG",
        "outputId": "53ac2d37-3582-4899-b65d-7c6e0aee39c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 52, 28)\n",
            "(None, 52, 32)\n",
            "(None, 26, 32)\n",
            "(None, 26, 16)\n",
            "(None, 13, 16)\n",
            "(None, 13, 16)\n",
            "(None, 26, 16)\n",
            "(None, 26, 32)\n",
            "(None, 52, 32)\n",
            "(None, 52, 28)\n",
            "Training log for 1dCNN autoencoder:\n",
            "Epoch 1/50\n",
            "23/23 - 2s - loss: 0.1518 - val_loss: 0.0500 - 2s/epoch - 66ms/step\n",
            "Epoch 2/50\n",
            "23/23 - 0s - loss: 0.0250 - val_loss: 0.0140 - 133ms/epoch - 6ms/step\n",
            "Epoch 3/50\n",
            "23/23 - 0s - loss: 0.0131 - val_loss: 0.0112 - 129ms/epoch - 6ms/step\n",
            "Epoch 4/50\n",
            "23/23 - 0s - loss: 0.0112 - val_loss: 0.0099 - 129ms/epoch - 6ms/step\n",
            "Epoch 5/50\n",
            "23/23 - 0s - loss: 0.0101 - val_loss: 0.0092 - 139ms/epoch - 6ms/step\n",
            "Epoch 6/50\n",
            "23/23 - 0s - loss: 0.0094 - val_loss: 0.0083 - 128ms/epoch - 6ms/step\n",
            "Epoch 7/50\n",
            "23/23 - 0s - loss: 0.0087 - val_loss: 0.0077 - 130ms/epoch - 6ms/step\n",
            "Epoch 8/50\n",
            "23/23 - 0s - loss: 0.0080 - val_loss: 0.0071 - 126ms/epoch - 5ms/step\n",
            "Epoch 9/50\n",
            "23/23 - 0s - loss: 0.0074 - val_loss: 0.0066 - 136ms/epoch - 6ms/step\n",
            "Epoch 10/50\n",
            "23/23 - 0s - loss: 0.0068 - val_loss: 0.0060 - 124ms/epoch - 5ms/step\n",
            "Epoch 11/50\n",
            "23/23 - 0s - loss: 0.0061 - val_loss: 0.0055 - 127ms/epoch - 6ms/step\n",
            "Epoch 12/50\n",
            "23/23 - 0s - loss: 0.0057 - val_loss: 0.0052 - 135ms/epoch - 6ms/step\n",
            "Epoch 13/50\n",
            "23/23 - 0s - loss: 0.0054 - val_loss: 0.0052 - 143ms/epoch - 6ms/step\n",
            "Epoch 14/50\n",
            "23/23 - 0s - loss: 0.0052 - val_loss: 0.0049 - 132ms/epoch - 6ms/step\n",
            "Epoch 15/50\n",
            "23/23 - 0s - loss: 0.0050 - val_loss: 0.0046 - 129ms/epoch - 6ms/step\n",
            "Epoch 16/50\n",
            "23/23 - 0s - loss: 0.0048 - val_loss: 0.0047 - 145ms/epoch - 6ms/step\n",
            "Epoch 17/50\n",
            "23/23 - 0s - loss: 0.0048 - val_loss: 0.0045 - 128ms/epoch - 6ms/step\n",
            "Epoch 18/50\n",
            "23/23 - 0s - loss: 0.0046 - val_loss: 0.0044 - 128ms/epoch - 6ms/step\n",
            "Epoch 19/50\n",
            "23/23 - 0s - loss: 0.0045 - val_loss: 0.0043 - 132ms/epoch - 6ms/step\n",
            "Epoch 20/50\n",
            "23/23 - 0s - loss: 0.0045 - val_loss: 0.0042 - 146ms/epoch - 6ms/step\n",
            "Epoch 21/50\n",
            "23/23 - 0s - loss: 0.0044 - val_loss: 0.0042 - 128ms/epoch - 6ms/step\n",
            "Epoch 22/50\n",
            "23/23 - 0s - loss: 0.0043 - val_loss: 0.0040 - 128ms/epoch - 6ms/step\n",
            "Epoch 23/50\n",
            "23/23 - 0s - loss: 0.0042 - val_loss: 0.0040 - 123ms/epoch - 5ms/step\n",
            "Epoch 24/50\n",
            "23/23 - 0s - loss: 0.0042 - val_loss: 0.0041 - 130ms/epoch - 6ms/step\n",
            "Epoch 25/50\n",
            "23/23 - 0s - loss: 0.0042 - val_loss: 0.0039 - 119ms/epoch - 5ms/step\n",
            "Epoch 26/50\n",
            "23/23 - 0s - loss: 0.0041 - val_loss: 0.0039 - 128ms/epoch - 6ms/step\n",
            "Epoch 27/50\n",
            "23/23 - 0s - loss: 0.0041 - val_loss: 0.0044 - 127ms/epoch - 6ms/step\n",
            "Epoch 28/50\n",
            "23/23 - 0s - loss: 0.0042 - val_loss: 0.0039 - 141ms/epoch - 6ms/step\n",
            "Epoch 29/50\n",
            "23/23 - 0s - loss: 0.0040 - val_loss: 0.0040 - 125ms/epoch - 5ms/step\n",
            "Epoch 30/50\n",
            "23/23 - 0s - loss: 0.0040 - val_loss: 0.0038 - 124ms/epoch - 5ms/step\n",
            "Epoch 31/50\n",
            "23/23 - 0s - loss: 0.0040 - val_loss: 0.0037 - 118ms/epoch - 5ms/step\n",
            "Epoch 32/50\n",
            "23/23 - 0s - loss: 0.0039 - val_loss: 0.0037 - 121ms/epoch - 5ms/step\n",
            "Epoch 33/50\n",
            "23/23 - 0s - loss: 0.0038 - val_loss: 0.0036 - 128ms/epoch - 6ms/step\n",
            "Epoch 34/50\n",
            "23/23 - 0s - loss: 0.0038 - val_loss: 0.0037 - 123ms/epoch - 5ms/step\n",
            "Epoch 35/50\n",
            "23/23 - 0s - loss: 0.0038 - val_loss: 0.0036 - 135ms/epoch - 6ms/step\n",
            "Epoch 36/50\n",
            "23/23 - 0s - loss: 0.0038 - val_loss: 0.0036 - 220ms/epoch - 10ms/step\n",
            "Epoch 37/50\n",
            "23/23 - 0s - loss: 0.0037 - val_loss: 0.0035 - 189ms/epoch - 8ms/step\n",
            "Epoch 38/50\n",
            "23/23 - 0s - loss: 0.0037 - val_loss: 0.0036 - 198ms/epoch - 9ms/step\n",
            "Epoch 39/50\n",
            "23/23 - 0s - loss: 0.0037 - val_loss: 0.0035 - 186ms/epoch - 8ms/step\n",
            "Epoch 40/50\n",
            "23/23 - 0s - loss: 0.0036 - val_loss: 0.0035 - 185ms/epoch - 8ms/step\n",
            "Epoch 41/50\n",
            "23/23 - 0s - loss: 0.0036 - val_loss: 0.0036 - 184ms/epoch - 8ms/step\n",
            "Epoch 42/50\n",
            "23/23 - 0s - loss: 0.0036 - val_loss: 0.0034 - 182ms/epoch - 8ms/step\n",
            "Epoch 43/50\n",
            "23/23 - 0s - loss: 0.0035 - val_loss: 0.0034 - 194ms/epoch - 8ms/step\n",
            "Epoch 44/50\n",
            "23/23 - 0s - loss: 0.0035 - val_loss: 0.0034 - 189ms/epoch - 8ms/step\n",
            "Epoch 45/50\n",
            "23/23 - 0s - loss: 0.0035 - val_loss: 0.0034 - 186ms/epoch - 8ms/step\n",
            "Epoch 46/50\n",
            "23/23 - 0s - loss: 0.0035 - val_loss: 0.0033 - 182ms/epoch - 8ms/step\n",
            "Epoch 47/50\n",
            "23/23 - 0s - loss: 0.0034 - val_loss: 0.0034 - 201ms/epoch - 9ms/step\n",
            "Epoch 48/50\n",
            "23/23 - 0s - loss: 0.0034 - val_loss: 0.0033 - 184ms/epoch - 8ms/step\n",
            "Epoch 49/50\n",
            "23/23 - 0s - loss: 0.0034 - val_loss: 0.0033 - 182ms/epoch - 8ms/step\n",
            "Epoch 50/50\n",
            "23/23 - 0s - loss: 0.0034 - val_loss: 0.0033 - 212ms/epoch - 9ms/step\n",
            "1dCNN autoencoder trained, with validation loss: 0.003296064445748925.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gettting the Global weights, needed for counterfactuals\n",
        "\n",
        "from _guided import get_global_weights\n",
        "from help_functions import evaluate\n",
        "pos_label = 1\n",
        "neg_label = 0\n",
        "\n",
        "step_weights = get_global_weights(\n",
        "        X,\n",
        "        y_classes,\n",
        "        cnnClassifier,\n",
        "        n_timesteps= n_timesteps,\n",
        "        n_features=n_features,\n",
        "        random_state=RANDOM_STATE,\n",
        ")\n"
      ],
      "metadata": {
        "id": "hysd9dxSsx9h",
        "outputId": "793dad58-0846-4467-f0eb-58beaf6fcb0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 4ms/step\n",
            "13/13 [==============================] - 0s 4ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 4ms/step\n",
            "13/13 [==============================] - 0s 4ms/step\n",
            "13/13 [==============================] - 0s 4ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 4ms/step\n",
            "13/13 [==============================] - 0s 5ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "13/13 [==============================] - 0s 4ms/step\n",
            "13/13 [==============================] - 0s 4ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step_weights"
      ],
      "metadata": {
        "id": "NkOmFZIBTCsK",
        "outputId": "4baea8a3-0fc8-40ed-fd5f-b5f0ebde3d1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from wildboar.explain import IntervalImportance\n",
        "#from LIMESegment.Utils.explanations import LIMESegment\n",
        "\n",
        "\n",
        "class ModifiedLatentCF:\n",
        "    \"\"\"Explanations by generating a counterfacutal sample in the latent space of\n",
        "    any autoencoder.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    Learning Time Series Counterfactuals via Latent Space Representations,\n",
        "    Wang, Z., Samsten, I., Mochaourab, R., Papapetrou, P., 2021.\n",
        "    in: International Conference on Discovery Science, pp. 369–384. https://doi.org/10.1007/978-3-030-88942-5_29\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        probability=0.5,\n",
        "        *,\n",
        "        tolerance=1e-6,\n",
        "        max_iter=100,\n",
        "        optimizer=None,\n",
        "        autoencoder=None,\n",
        "        margin_weight=1.0,  # weighted_steps_weight = 1 - pred_margin_weight\n",
        "        random_state=None,\n",
        "        bandwidth,\n",
        "        weighted_steps_weight,\n",
        "        data,\n",
        "        step_weights\n",
        "    ):\n",
        "        self.optimizer_ = (\n",
        "            tf.optimizers.Adam(learning_rate=1e-4) if optimizer is None else optimizer\n",
        "        )\n",
        "        #self.x_axis_eights = x_axis_eights\n",
        "        #self.y_axis_eights = y_axis_eights\n",
        "        self.data = data\n",
        "        self.mse_loss_ = keras.losses.MeanSquaredError()\n",
        "        self.probability_ = tf.constant([probability])\n",
        "        self.tolerance_ = tf.constant(tolerance)\n",
        "        self.max_iter = max_iter\n",
        "        self.autoencoder = autoencoder\n",
        "        self.random_state = random_state\n",
        "        self.weighted_steps_weight = weighted_steps_weight\n",
        "        self.step_weights = step_weights\n",
        "\n",
        "        # Weights of the different loss components\n",
        "        self.margin_weight = margin_weight\n",
        "        self.kde_weight = tf.cast(1 - self.margin_weight-self.weighted_steps_weight,tf.float32)\n",
        "        if (self.weighted_steps_weight+self.margin_weight)>1.0:\n",
        "           raise ValueError(\"(weighted_steps_weight + margin_weight) should be less that 1.0\")\n",
        "\n",
        "        self.bandwidth = bandwidth\n",
        "\n",
        "    def fit(self, model):\n",
        "        \"\"\"Fit a new counterfactual explainer to the model\n",
        "\n",
        "        Paramaters\n",
        "        ----------\n",
        "\n",
        "        model : keras.Model\n",
        "            The model\n",
        "        \"\"\"\n",
        "        if self.autoencoder:\n",
        "            (\n",
        "                encode_input,\n",
        "                encode_output,\n",
        "                decode_input,\n",
        "                decode_output,\n",
        "            ) = extract_encoder_decoder(self.autoencoder)\n",
        "            self.decoder_ = keras.Model(inputs=decode_input, outputs=decode_output)\n",
        "            self.encoder_ = keras.Model(inputs=encode_input, outputs=encode_output)\n",
        "        else:\n",
        "            self.decoder_ = None\n",
        "            self.encoder_ = None\n",
        "        self.model_ = model\n",
        "        return self\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"Compute the difference between the desired and actual probability\n",
        "\n",
        "        Parameters\n",
        "        ---------\n",
        "        x : Variable\n",
        "            Variable of the sample\n",
        "        \"\"\"\n",
        "        if self.autoencoder is None:\n",
        "            z = x\n",
        "        else:\n",
        "            z = self.decoder_(x)\n",
        "\n",
        "        return self.model_(z)\n",
        "\n",
        "    # The \"pred_margin_loss\" is designed to measure the prediction probability to the desired decision boundary\n",
        "    def pred_margin_mse(self, prediction):\n",
        "        return self.mse_loss_(self.probability_, prediction)\n",
        "\n",
        "    # An auxiliary MAE loss function to measure the proximity with step_weights\n",
        "    def weighted_mae(self, original_sample, cf_sample, step_weights):\n",
        "        return tf.math.reduce_mean(\n",
        "            tf.math.multiply(tf.math.abs(original_sample - cf_sample), step_weights)\n",
        "        )\n",
        "\n",
        "    # An auxiliary normalized L2 loss function to measure the proximity with step_weights\n",
        "    def weighted_normalized_l2(self, original_sample, cf_sample, step_weights):\n",
        "        var_diff = tf.math.reduce_variance(original_sample - cf_sample)\n",
        "        var_orig = tf.math.reduce_variance(original_sample)\n",
        "        var_cf = tf.math.reduce_variance(cf_sample)\n",
        "\n",
        "        normalized_l2 = 0.5 * var_diff / (var_orig + var_cf)\n",
        "        return tf.math.reduce_mean(\n",
        "            tf.math.multiply(\n",
        "                normalized_l2,\n",
        "                step_weights,\n",
        "            )\n",
        "        )\n",
        "    #x_axis_eights*self.step_weights_x,use_scotts_rule=False,use_silvermans_rule=True,manual_bandwidth = 0.1\n",
        "    def train_gaussian_kde(self, data, use_scotts_rule,use_silvermans_rule, manual_bandwidth ):\n",
        "      \"\"\"\n",
        "      Train a Gaussian KDE on the provided data.\n",
        "\n",
        "      :param data: Multivariate data points used for KDE (2D Tensor).\n",
        "      :param bandwidth: The bandwidth of the kernel (float).\n",
        "      :return: A function that represents the trained KDE.\n",
        "      \"\"\"\n",
        "\n",
        "      n = tf.cast(tf.shape(data)[0], tf.float32)\n",
        "      d = tf.cast(tf.shape(data)[1], tf.float32)\n",
        "      def kde_fn( x_points):\n",
        "        \"\"\"\n",
        "        Compute the density estimation for given points using the trained KDE.\n",
        "\n",
        "        :param x_points: Points where the density should be estimated (2D Tensor).\n",
        "        :return: Density estimates (Tensor).\n",
        "        \"\"\"\n",
        "        d = tf.cast(tf.shape(data)[1], tf.float32)\n",
        "\n",
        "        data_exp =  tf.expand_dims(data, axis=0)\n",
        "        print(f'x_points shape = {x_points.shape}')\n",
        "        x_points_exp = tf.reshape(x_points, (tf.shape(x_points)[0], 28, 1))\n",
        "\n",
        "        x_points_exp = tf.expand_dims(x_points_exp, axis=1)\n",
        "        if use_scotts_rule:\n",
        "          sigma = tf.math.reduce_std(data)\n",
        "          sigma = tf.cast(sigma,tf.float32)\n",
        "          bandwidth = n ** (-1.0 / (d + 4)) * sigma\n",
        "        elif use_silvermans_rule:\n",
        "          sigma = tf.math.reduce_std(data)\n",
        "          bandwidth = (4 * sigma**5 / (3 * n)) ** (1/5)\n",
        "        else:\n",
        "          if manual_bandwidth is None:\n",
        "            raise ValueError(\"Manual bandwidth must be provided if not using Scott's Rule.\")\n",
        "          bandwidth = manual_bandwidth\n",
        "\n",
        "        bandwidth = tf.cast(bandwidth, tf.float32)\n",
        "        x_points_exp = tf.cast(x_points_exp,tf.float32)\n",
        "        data_exp= tf.cast(data_exp, tf.float32)\n",
        "        diff = x_points_exp - data_exp\n",
        "        norm = tf.reduce_sum(diff ** 2, axis=2)\n",
        "        kernel_val = tf.exp(-norm / (2.0 * bandwidth ** 2))\n",
        "\n",
        "\n",
        "        d = tf.constant(d,tf.float32)\n",
        "        density = tf.reduce_mean(kernel_val, axis=1) / (bandwidth * tf.sqrt(2.0 * np.pi * d))\n",
        "        return density\n",
        "\n",
        "      return kde_fn\n",
        "\n",
        "    def gaussian_kde_logpdf(self, kde_fn, x_points):\n",
        "      \"\"\"\n",
        "      Evaluate the logpdf of the given points using the trained KDE function.\n",
        "\n",
        "      :param kde_fn: Trained KDE function.\n",
        "      :param x_points: Points to evaluate the logpdf (2D Tensor).\n",
        "      :return: Log of the density estimates (Tensor).\n",
        "      \"\"\"\n",
        "      density = kde_fn(x_points)\n",
        "      return tf.math.log(density)\n",
        "\n",
        "\n",
        "    # additional input of step_weights\n",
        "    def compute_loss(self,original_sample, z_search, target_label, kde_stop):\n",
        "        loss = tf.zeros(shape=())\n",
        "        decoded = self.decoder_(z_search) if self.autoencoder is not None else z_search\n",
        "        pred = self.model_(decoded)[:, target_label]\n",
        "\n",
        "        #margin loss (y-τ)\n",
        "        margin_loss = self.pred_margin_mse(pred)\n",
        "        loss += self.margin_weight * margin_loss\n",
        "\n",
        "        kde_diffrences = []\n",
        "        for dimention in range(decoded.shape[2]):\n",
        "          data_dimention = self.data[:,:,dimention]\n",
        "          data_dimention = data_dimention[:,:,np.newaxis]\n",
        "          kde = self.train_gaussian_kde(data = data_dimention,use_scotts_rule=False,use_silvermans_rule=False,manual_bandwidth = self.bandwidth)\n",
        "          mean_log_likelihood = tf.cast(tf.reduce_mean(self.gaussian_kde_logpdf(kde, x_points = (data_dimention))),tf.float32)\n",
        "\n",
        "          decoded_dimention = decoded[:,:,dimention]\n",
        "          decoded_dimention = decoded_dimention[:,:,np.newaxis]\n",
        "          log_likelihood_of_sample = tf.cast(self.gaussian_kde_logpdf(kde, x_points = (decoded_dimention)),tf.float32)\n",
        "\n",
        "          kde_loss = tf.cast((mean_log_likelihood - log_likelihood_of_sample),tf.float32)\n",
        "          kde_diffrences.append(kde_loss)\n",
        "        kde_total_loss = tf.math.add_n(kde_diffrences)\n",
        "        kde_total_loss = tf.math.abs(kde_total_loss)\n",
        "        print(kde_total_loss)\n",
        "        loss +=self.kde_weight *kde_total_loss\n",
        "\n",
        "\n",
        "        weighted_steps_loss = self.weighted_mae(\n",
        "            original_sample=tf.cast(original_sample, dtype=tf.float32),\n",
        "            cf_sample=tf.cast(decoded, dtype=tf.float32),\n",
        "            step_weights=tf.cast(step_weights, tf.float32),\n",
        "        )\n",
        "        loss += self.weighted_steps_weight * weighted_steps_loss\n",
        "\n",
        "        return loss, margin_loss, kde_loss, kde_stop\n",
        "\n",
        "    # TODO: compatible with the counterfactuals of wildboar\n",
        "    #       i.e., define the desired output target per label\n",
        "\n",
        "\n",
        "    def transform(self, x, pred_labels):\n",
        "        \"\"\"Generate counterfactual explanations\n",
        "\n",
        "        x : array-like of shape [n_samples, n_timestep, n_dims]\n",
        "            The samples\n",
        "        \"\"\"\n",
        "\n",
        "        result_samples = np.empty(x.shape)\n",
        "        losses = np.empty(x.shape[0])\n",
        "        # `weights_all` needed for debugging\n",
        "        weights_all = np.empty((x.shape[0], 1, x.shape[1], x.shape[2]))\n",
        "        for i in range(x.shape[0]):\n",
        "            print(f\"sample {i+1} is beeing transformed.\")\n",
        "            kde_stop = False\n",
        "\n",
        "            x_sample, loss = self._transform_sample(\n",
        "                x[np.newaxis, i], pred_labels[i],kde_stop\n",
        "            )\n",
        "\n",
        "            result_samples[i] = x_sample\n",
        "            losses[i] = loss\n",
        "            weights_all[i] = step_weights\n",
        "\n",
        "        print(f\"{i+1} samples been transformed, in total.\")\n",
        "\n",
        "        return result_samples, losses, weights_all\n",
        "\n",
        "    def _transform_sample(self, x, pred_label,kde_stop):\n",
        "        \"\"\"Generate counterfactual explanations(z))\"\"\"\n",
        "        # TODO: check_is_fitted(self)\n",
        "        if self.autoencoder is not None:\n",
        "            z = tf.Variable(self.encoder_(x))\n",
        "        else:\n",
        "            z = tf.Variable(x, dtype=tf.float32)\n",
        "\n",
        "        it = 0\n",
        "        target_label = 1 - pred_label  # for binary classification\n",
        "\n",
        "        #def compute_loss(self,original_sample, z_search, target_label)\n",
        "        with tf.GradientTape(persistent = True) as tape:\n",
        "            loss, pred_margin_loss, kde_loss, kde_stop = self.compute_loss(\n",
        "                x, z,  target_label,kde_stop\n",
        "            )\n",
        "        if self.autoencoder is not None:\n",
        "            pred = self.model_(self.decoder_(z))\n",
        "        else:\n",
        "            pred = self.model_(z)\n",
        "\n",
        "\n",
        "        while (\n",
        "            (loss > self.tolerance_\n",
        "            and pred[:, target_label] < self.probability_)\n",
        "            and (it < self.max_iter if self.max_iter else True)\n",
        "            ) :\n",
        "            # Get gradients of loss wrt the sample\n",
        "            grads = tape.gradient(loss, z)\n",
        "            # Update the weights of the sample\n",
        "            self.optimizer_.apply_gradients([(grads, z)])\n",
        "            del tape\n",
        "\n",
        "            #self,original_sample, z_search, target_label\n",
        "            with tf.GradientTape(persistent=True) as tape:\n",
        "                loss, pred_margin_loss, kde_loss, kde_stop = self.compute_loss(\n",
        "                    x, z,  target_label,kde_stop\n",
        "                )\n",
        "\n",
        "            kde_loss = tf.convert_to_tensor(kde_loss, dtype=tf.float32)\n",
        "            grads = tape.gradient(loss, z)\n",
        "            # Optionally, compute and log gradients for individual components\n",
        "            kde_grads = tape.gradient(kde_loss, z)\n",
        "            margin_grads = tape.gradient(pred_margin_loss, z)\n",
        "\n",
        "\n",
        "            it += 1\n",
        "            if it % 50 == 0:\n",
        "              print(f'Currently on iteration: {it}.')\n",
        "            #   # print(f'kde loss : {kde_loss}')\n",
        "            #   # print(f'margin loss : {pred_margin_loss}')\n",
        "            #   # print(f'loss : {loss}')\n",
        "\n",
        "            #   if kde_grads is  None:\n",
        "            #     print(\"KDE Gradients are None.\")\n",
        "            if self.autoencoder is not None:\n",
        "                pred = self.model_(self.decoder_(z))\n",
        "            else:\n",
        "                pred = self.model_(z)\n",
        "\n",
        "        # # uncomment for debug\n",
        "        # print(\n",
        "        #     f\"current loss: {loss}, pred_margin_loss: {pred_margin_loss}, weighted_steps_loss: {weighted_steps_loss}, pred prob:{pred}, iter: {it}. \\n\"\n",
        "        # )\n",
        "\n",
        "        res = z.numpy() if self.autoencoder is None else self.decoder_(z).numpy()\n",
        "        return res, float(loss)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bDr0XgBKZGPU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.9,\n",
        "    tolerance=1e-6,\n",
        "    max_iter=500,\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
        "    autoencoder = autoencoder,\n",
        "    margin_weight=0.6,\n",
        "    random_state= RANDOM_STATE,\n",
        "    bandwidth = 0.5,\n",
        "    weighted_steps_weight = 0.2,\n",
        "    data = X_train[y_train_classes == 1],\n",
        "    step_weights = step_weights\n",
        "    )\n",
        "cf_model.fit(cnnClassifier)\n",
        "\n",
        "\n",
        "y_neg = y_classes[y_classes == 0][10:15]\n",
        "X_neg = X[y_classes == 0][10:15]\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
        "    cf_embeddings, losses, weights = cf_model.transform(x = X_neg,pred_labels = y_neg)\n"
      ],
      "metadata": {
        "id": "f-Xy39aj8q9S",
        "outputId": "256715f7-a969-43e7-cd6e-e3d6037b62d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample 1 is beeing transformed.\n",
            "x_points shape = (132, 52, 1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 6864 values, but the requested shape has 3696 [Op:Reshape]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-4c19cb36c011>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRuntimeWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcf_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_neg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-49b319f3f4a5>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, x, pred_labels)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mkde_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             x_sample, loss = self._transform_sample(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkde_stop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             )\n",
            "\u001b[0;32m<ipython-input-34-49b319f3f4a5>\u001b[0m in \u001b[0;36m_transform_sample\u001b[0;34m(self, x, pred_label, kde_stop)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m#def compute_loss(self,original_sample, z_search, target_label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersistent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             loss, pred_margin_loss, kde_loss, kde_stop = self.compute_loss(\n\u001b[0m\u001b[1;32m    270\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtarget_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkde_stop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             )\n",
            "\u001b[0;32m<ipython-input-34-49b319f3f4a5>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, original_sample, z_search, target_label, kde_stop)\u001b[0m\n\u001b[1;32m    200\u001b[0m           \u001b[0mdata_dimention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dimention\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m           \u001b[0mkde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_gaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dimention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_scotts_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_silvermans_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmanual_bandwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbandwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m           \u001b[0mmean_log_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_kde_logpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_dimention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m           \u001b[0mdecoded_dimention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdimention\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-49b319f3f4a5>\u001b[0m in \u001b[0;36mgaussian_kde_logpdf\u001b[0;34m(self, kde_fn, x_points)\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLog\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdensity\u001b[0m \u001b[0mestimates\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \"\"\"\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0mdensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkde_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdensity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-49b319f3f4a5>\u001b[0m in \u001b[0;36mkde_fn\u001b[0;34m(x_points)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mdata_exp\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'x_points shape = {x_points.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mx_points_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mx_points_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_points_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 6864 values, but the requested shape has 3696 [Op:Reshape]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#with learning rate = 0.001, 500 iterations, bandwidth = 0.1,margin_weight=0.6,weighted_steps_weight = 0.2,kse_weight = 0.2\n",
        "for i in range(5):\n",
        "  i=i+30\n",
        "  print(\"actual\")\n",
        "  visualise_digit(X_neg,y_neg,i,figsize = (5,5))\n",
        "  print(\"counterfactual\")\n",
        "  visualise_digit(cf_embeddings,y_neg,i,figsize = (5,5))\n"
      ],
      "metadata": {
        "id": "UbvQjP1RpiYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validity\n",
        "cf_pred = cnnClassifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "cf_pred_labels = cf_pred\n",
        "for idx in range(cf_pred_labels.shape[0]):\n",
        "  if cf_pred_labels[idx] > 0.5:\n",
        "    cf_pred_labels[idx] = 1\n",
        "  else:\n",
        "    cf_pred_labels[idx] = 0\n",
        "\n",
        "\n",
        "print(f'Transformation_finished with validity_score = {validity_score(y_neg,cf_pred_labels)}')"
      ],
      "metadata": {
        "id": "Ov4igLqcorG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating proximity withour absolute\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "total_mse = 0\n",
        "probability = 0.9\n",
        "for idx in range(cf_embeddings.shape[0]):\n",
        "    counterfactual = cf_embeddings[idx,np.newaxis]\n",
        "    prediction = cnnClassifier.predict(counterfactual)[:, 1]\n",
        "    mse = MeanSquaredError()\n",
        "    mse_dist = mse(probability, prediction).numpy()\n",
        "    total_mse +=mse_dist\n",
        "mean_mse = total_mse /cf_embeddings.shape[0]\n",
        "print(f\"The Mean MSE of the data is: {mean_mse} \")"
      ],
      "metadata": {
        "id": "Nvlack0n40dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The Mean MSE of the data is: {mean_mse} \")"
      ],
      "metadata": {
        "id": "DaGvoFKBjyX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating proximity with absolute\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "total = 0\n",
        "probability = 0.9\n",
        "for idx in range(cf_embeddings.shape[0]):\n",
        "    counterfactual = cf_embeddings[idx,np.newaxis]\n",
        "    prediction = cnnClassifier.predict(counterfactual)[:, 1]\n",
        "    dist = abs(prediction - probability)\n",
        "    total +=dist\n",
        "mean_mse = total /cf_embeddings.shape[0]\n",
        "print(f\"The Mean MSE of the data is: {mean_mse} \")"
      ],
      "metadata": {
        "id": "oK3o9SQB41a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The Mean MSE of the data is: {mean_mse} \")"
      ],
      "metadata": {
        "id": "JmStyUVjj0-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Proximity\n",
        "def euclidean_distance(X, cf_samples):\n",
        "    paired_distances = np.linalg.norm(X - cf_samples, axis=1)\n",
        "    return np.mean(paired_distances)\n",
        "euclidean_distance(X_neg, cf_embeddings)"
      ],
      "metadata": {
        "id": "ZTsPvh1lotsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "diffrences_from_abnormal = []\n",
        "diffrences_from_normal = []\n",
        "for dimention in range(cf_embeddings.shape[2]):\n",
        "\n",
        "\n",
        "  abnormal_data = X[y_classes == 1][:,:,dimention]\n",
        "  normal_data = X[y_classes == 0][:,:,dimention]\n",
        "  counterf_data = cf_embeddings[:,:,dimention]\n",
        "\n",
        "  #get the kernel for every dimention of the trained\n",
        "  kernel = gaussian_kde(abnormal_data.T,bw_method=None)\n",
        "\n",
        "  #get all the log likelihoods\n",
        "  log_likelihood_abnormal = np.mean(kernel.logpdf(abnormal_data.T))\n",
        "  log_likelihood_normal = np.mean(kernel.logpdf(normal_data.T))\n",
        "  log_likelihood_counterfactual = np.mean(kernel.logpdf(counterf_data.T))\n",
        "\n",
        "  #get the diffrences from the counterfactuals\n",
        "  diff_from_abnormal = abs(log_likelihood_counterfactual-log_likelihood_abnormal)\n",
        "  diffrences_from_abnormal.append(diff_from_abnormal)\n",
        "\n",
        "  diff_from_normal = abs(log_likelihood_counterfactual-log_likelihood_normal)\n",
        "  diffrences_from_normal.append(diff_from_normal)\n"
      ],
      "metadata": {
        "id": "7GSjwx8w4liQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diffrences_from_normal"
      ],
      "metadata": {
        "id": "G6rd-6JvFLP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diffrences_from_abnormal"
      ],
      "metadata": {
        "id": "7j6tO69OFNdv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}