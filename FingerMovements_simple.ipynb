{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stellagerantoni/LatentCfMultivariate/blob/main/FingerMovements_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/stellagerantoni/LatentCfMultivariate"
      ],
      "metadata": {
        "id": "1fwOXGEl_ine"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wildboar\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q stumpy\n",
        "!pip install -q fastdtw\n",
        "!pip install aeon"
      ],
      "metadata": {
        "id": "89L3kts7CCan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "from aeon.datasets import load_classification\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "%cd '/content/LatentCfMultivariate'\n",
        "from _guided import ModifiedLatentCF\n",
        "from help_functions import *\n",
        "from keras_models import *"
      ],
      "metadata": {
        "id": "Bdkpan5lCGRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n",
        "RANDOM_STATE = 39"
      ],
      "metadata": {
        "id": "GJE1AxFnE51S"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **FUNCTIONS**"
      ],
      "metadata": {
        "id": "IHBw9E_4Zm5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset):\n",
        "  X, y = load_classification(dataset)\n",
        "  if dataset == 'FingerMovements':\n",
        "    pos = 'left'\n",
        "    neg = 'right'\n",
        "\n",
        "\n",
        "  print(\" Shape of X = \", X.shape)\n",
        "  print(\" Shape of y = \", y.shape)\n",
        "  #print(\" Meta data = \", meta_data)\n",
        "  # Convert positive and negative labels to 1 and 0\n",
        "  pos_label, neg_label = 1, 0\n",
        "  if pos != pos_label:\n",
        "      y[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "  if neg != neg_label:\n",
        "      y[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "  y = y.astype(int)\n",
        "  print(f\"\\n X[:1] = \\n{X[:1]}\")\n",
        "  return X,y,pos_label, neg_label"
      ],
      "metadata": {
        "id": "QsJJktx22dXs"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ACTUALL CODE**\n",
        "datasets available : 'Heartbeat', 'SelfRegulationSCP1'"
      ],
      "metadata": {
        "id": "6vVfmpyuZyC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 39\n",
        "X,y,pos_label,neg_label = load_dataset('FingerMovements')\n",
        "X = X.transpose(0,2,1)\n",
        "print(f'shape of X = {X.shape}')\n",
        "print(f'shape of y = {y.shape}')\n",
        "#print(f'data imformation = {data_information}')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
        "print(f'shape of X train = {X_train.shape}')\n",
        "print(f'shape of y train = {y_train.shape}')"
      ],
      "metadata": {
        "id": "W4m9pwqyVY1b",
        "outputId": "6d2fb30a-b76e-4f99-8ded-340e18c61985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Shape of X =  (416, 28, 50)\n",
            " Shape of y =  (416,)\n",
            "\n",
            " X[:1] = \n",
            "[[[41.8 44.8 47.1 ... 69.8 72.6 76.1]\n",
            "  [55.2 53.8 59.9 ... 17.5 28.  12.1]\n",
            "  [-8.6 -3.6 14.4 ... 23.3 35.9 23.2]\n",
            "  ...\n",
            "  [16.9 24.5 24.5 ... 51.9 59.6 57.3]\n",
            "  [42.2 35.  41.7 ... 51.5 58.5 46.9]\n",
            "  [13.  26.6 52.5 ... -3.5 -3.2 -2.6]]]\n",
            "shape of X = (416, 50, 28)\n",
            "shape of y = (416,)\n",
            "shape of X train = (332, 50, 28)\n",
            "shape of y train = (332,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upsample the minority class\n",
        "\n",
        "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "print(f'before: {class_counts}')\n",
        "X_train,y_train = upsample_minority_multivariate(X_train,y_train)\n",
        "X,y = upsample_minority_multivariate(X, y)\n",
        "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "print(f'after: {class_counts}')"
      ],
      "metadata": {
        "id": "Q2v7QdrHieA8",
        "outputId": "d7ea0d45-09e2-4858-a729-ba2ad74b92e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before: [166 166]\n",
            "after: [166 166]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing and Padding all our data\n",
        "#Padding needed for autoencoder\n",
        "\n",
        "n_training,n_timesteps, n_features= X_train.shape\n",
        "\n",
        "X, trained_scaler =  normalize_multivariate(data=X, n_timesteps=n_timesteps, n_features = n_features)\n",
        "X_train_processed, trained_scaler =  normalize_multivariate(data=X_train, n_timesteps=n_timesteps, n_features = n_features)\n",
        "X_test_processed, _ =  normalize_multivariate(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler, n_features = n_features)\n",
        "\n",
        "X, padding_size = conditional_pad_multivariate(X)\n",
        "X_train_processed_padded, padding_size = conditional_pad_multivariate(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad_multivariate(X_test_processed)\n",
        "\n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "print(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n",
        "\n",
        "#check the processing (0,1) min should be min 0 and max should be max 1\n",
        "print(f\"\\nmin value = {np.min(X_train)}, max value = {np.max(X_train)}\")\n",
        "print(f\"min value normalized = {np.min(X_train_processed)}, max value normalized= {np.max(X_train_processed)}\")\n",
        "\n",
        "#check that padding paddes the right dimention\n",
        "print(f\"\\nX_train.shape = {X_train.shape}\" )\n",
        "print(f\"X_train_processed_padded.shape = {X_train_processed_padded.shape}\")\n"
      ],
      "metadata": {
        "id": "00Q9QjKy7wEZ",
        "outputId": "f7a7f1f5-b91e-4462-880e-ca826b81f8d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data pre-processed, original #timesteps=50, padded #timesteps=52.\n",
            "\n",
            "min value = -132.1, max value = 205.1\n",
            "min value normalized = 0.0, max value normalized= 1.0\n",
            "\n",
            "X_train.shape = (332, 50, 28)\n",
            "X_train_processed_padded.shape = (332, 52, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_validation, y_train, y_validation = train_test_split(X_train_processed_padded, y_train, test_size=0.2, random_state=RANDOM_STATE, stratify=y_train)"
      ],
      "metadata": {
        "id": "1mYFZmsvtB9q"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the two forms of labels needed\n",
        "#-the y_classes (1,0,1,0,...)\n",
        "#-the y (one hot encoded)\n",
        "\n",
        "print(f'X_train = {X_train.shape}')\n",
        "print(f'X_validation = {X_validation.shape}')\n",
        "print(f'X_test = {X_test.shape}')\n",
        "\n",
        "y_classes = y\n",
        "y_train_classes = y_train\n",
        "y_validation_classes = y_validation\n",
        "y_test_classes = y_test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, len(np.unique(y)))\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_validation = to_categorical(y_validation, len(np.unique(y_validation)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))\n",
        "\n",
        "print(f'\\ny_train_classes = {y_train_classes.shape}, y_validation_classes = {y_validation_classes.shape}, y_test_classes = {y_test_classes.shape}')\n",
        "print(f'y_train = {y_train.shape}, y_validation = {y_validation.shape}, y_test= {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9b2F-vytxzU",
        "outputId": "755c7fe3-34b2-424b-8399-dbec1e9015f8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train = (265, 52, 28)\n",
            "X_validation = (67, 52, 28)\n",
            "X_test = (84, 50, 28)\n",
            "\n",
            "y_train_classes = (265,), y_validation_classes = (67,), y_test_classes = (84,)\n",
            "y_train = (265, 2), y_validation = (67, 2), y_test= (84, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ## LatentCF++ models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "###############################################\n",
        "# ### 1dCNN classifier\n",
        "\n",
        "cnnClassifier = Classifier(\n",
        "    n_timesteps_padded, n_features, n_output=2, add_dense_layer = False\n",
        ")\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "cnnClassifier.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=15, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for LSTM-FCN classifier:\")\n",
        "classifier_history = cnnClassifier.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=150,\n",
        "    batch_size=12,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_validation, y_validation),\n",
        "    callbacks=[early_stopping_accuracy],\n",
        ")\n",
        "\n",
        "y_pred = cnnClassifier.predict(X_test_processed_padded)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "print(f\"LSTM-FCN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "    confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "    index=[\"True:1\", \"True:0\"],\n",
        "    columns=[\"Pred:1\", \"Pred:0\"],\n",
        ")\n",
        "print(confusion_matrix_df)\n"
      ],
      "metadata": {
        "id": "yNkKTXe6IIyF",
        "outputId": "c8a624d4-455e-4ec4-8d75-fc8130d36866",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training log for LSTM-FCN classifier:\n",
            "Epoch 1/150\n",
            "23/23 [==============================] - 2s 21ms/step - loss: 0.8307 - accuracy: 0.5132 - val_loss: 0.7577 - val_accuracy: 0.4925\n",
            "Epoch 2/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6913 - accuracy: 0.6226 - val_loss: 0.7282 - val_accuracy: 0.5224\n",
            "Epoch 3/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6332 - accuracy: 0.7132 - val_loss: 0.7123 - val_accuracy: 0.6567\n",
            "Epoch 4/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7008 - accuracy: 0.6189 - val_loss: 0.7063 - val_accuracy: 0.6418\n",
            "Epoch 5/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5797 - accuracy: 0.7585 - val_loss: 0.7008 - val_accuracy: 0.6567\n",
            "Epoch 6/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5776 - accuracy: 0.7736 - val_loss: 0.7309 - val_accuracy: 0.4925\n",
            "Epoch 7/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.7321 - val_loss: 0.7398 - val_accuracy: 0.5075\n",
            "Epoch 8/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7774 - val_loss: 0.7111 - val_accuracy: 0.5224\n",
            "Epoch 9/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.8264 - val_loss: 0.7142 - val_accuracy: 0.5672\n",
            "Epoch 10/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.8642 - val_loss: 0.6915 - val_accuracy: 0.5821\n",
            "Epoch 11/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.8038 - val_loss: 0.6321 - val_accuracy: 0.8358\n",
            "Epoch 12/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.8226 - val_loss: 0.6369 - val_accuracy: 0.6866\n",
            "Epoch 13/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8717 - val_loss: 0.6168 - val_accuracy: 0.7463\n",
            "Epoch 14/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8906 - val_loss: 0.6924 - val_accuracy: 0.5821\n",
            "Epoch 15/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.8038 - val_loss: 0.6033 - val_accuracy: 0.7015\n",
            "Epoch 16/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8906 - val_loss: 0.5943 - val_accuracy: 0.6716\n",
            "Epoch 17/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8868 - val_loss: 0.5505 - val_accuracy: 0.7761\n",
            "Epoch 18/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.8830 - val_loss: 0.6632 - val_accuracy: 0.5970\n",
            "Epoch 19/150\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3999 - accuracy: 0.8717 - val_loss: 0.5669 - val_accuracy: 0.7612\n",
            "Epoch 20/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8868 - val_loss: 0.5460 - val_accuracy: 0.7910\n",
            "Epoch 21/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3216 - accuracy: 0.9019 - val_loss: 0.5218 - val_accuracy: 0.7612\n",
            "Epoch 22/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2970 - accuracy: 0.9283 - val_loss: 0.7429 - val_accuracy: 0.6119\n",
            "Epoch 23/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3028 - accuracy: 0.9321 - val_loss: 0.4906 - val_accuracy: 0.8060\n",
            "Epoch 24/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2985 - accuracy: 0.9245 - val_loss: 0.4710 - val_accuracy: 0.8806\n",
            "Epoch 25/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2904 - accuracy: 0.9245 - val_loss: 1.4172 - val_accuracy: 0.5075\n",
            "Epoch 26/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3200 - accuracy: 0.9019 - val_loss: 0.4673 - val_accuracy: 0.7910\n",
            "Epoch 27/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2905 - accuracy: 0.9434 - val_loss: 1.4751 - val_accuracy: 0.5075\n",
            "Epoch 28/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8453 - val_loss: 0.6076 - val_accuracy: 0.7164\n",
            "Epoch 29/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3336 - accuracy: 0.8981 - val_loss: 0.5257 - val_accuracy: 0.7612\n",
            "Epoch 30/150\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.2775 - accuracy: 0.9170 - val_loss: 0.7431 - val_accuracy: 0.6567\n",
            "Epoch 31/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2690 - accuracy: 0.9434 - val_loss: 0.4869 - val_accuracy: 0.8209\n",
            "Epoch 32/150\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.2349 - accuracy: 0.9736 - val_loss: 0.4467 - val_accuracy: 0.8060\n",
            "Epoch 33/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2885 - accuracy: 0.9245 - val_loss: 0.4897 - val_accuracy: 0.7761\n",
            "Epoch 34/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2407 - accuracy: 0.9547 - val_loss: 1.7633 - val_accuracy: 0.5075\n",
            "Epoch 35/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2567 - accuracy: 0.9623 - val_loss: 1.1321 - val_accuracy: 0.5821\n",
            "Epoch 36/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2356 - accuracy: 0.9547 - val_loss: 0.5804 - val_accuracy: 0.7612\n",
            "Epoch 37/150\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.2141 - accuracy: 0.9774 - val_loss: 0.4659 - val_accuracy: 0.8806\n",
            "Epoch 38/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2468 - accuracy: 0.9509 - val_loss: 0.4943 - val_accuracy: 0.7910\n",
            "Epoch 39/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1967 - accuracy: 0.9887 - val_loss: 1.3935 - val_accuracy: 0.6119\n",
            "3/3 [==============================] - 0s 7ms/step\n",
            "LSTM-FCN classifier trained, with validation accuracy 0.44047619047619047.\n",
            "        Pred:1  Pred:0\n",
            "True:1      18      24\n",
            "True:0      23      19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder( n_timesteps_padded,n_features,32)\n",
        "optimizer = keras.optimizers.Adam(lr=0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, restore_best_weights=True)\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    batch_size=12,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    validation_data=(X_validation, X_validation),\n",
        "    callbacks=[early_stopping])\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history['val_loss'])\n",
        "print(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")\n"
      ],
      "metadata": {
        "id": "E6IxH8BLEKFG",
        "outputId": "64f26b28-e378-4394-a9d5-c70d81a8c926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 52, 28)\n",
            "(None, 52, 32)\n",
            "(None, 26, 32)\n",
            "(None, 26, 16)\n",
            "(None, 13, 16)\n",
            "(None, 13, 16)\n",
            "(None, 26, 16)\n",
            "(None, 26, 32)\n",
            "(None, 52, 32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 52, 28)\n",
            "Training log for 1dCNN autoencoder:\n",
            "Epoch 1/50\n",
            "23/23 - 10s - loss: 0.1518 - val_loss: 0.0500 - 10s/epoch - 431ms/step\n",
            "Epoch 2/50\n",
            "23/23 - 0s - loss: 0.0250 - val_loss: 0.0140 - 271ms/epoch - 12ms/step\n",
            "Epoch 3/50\n",
            "23/23 - 0s - loss: 0.0131 - val_loss: 0.0112 - 178ms/epoch - 8ms/step\n",
            "Epoch 4/50\n",
            "23/23 - 0s - loss: 0.0112 - val_loss: 0.0099 - 186ms/epoch - 8ms/step\n",
            "Epoch 5/50\n",
            "23/23 - 0s - loss: 0.0101 - val_loss: 0.0092 - 272ms/epoch - 12ms/step\n",
            "Epoch 6/50\n",
            "23/23 - 0s - loss: 0.0094 - val_loss: 0.0083 - 284ms/epoch - 12ms/step\n",
            "Epoch 7/50\n",
            "23/23 - 0s - loss: 0.0087 - val_loss: 0.0077 - 393ms/epoch - 17ms/step\n",
            "Epoch 8/50\n",
            "23/23 - 0s - loss: 0.0080 - val_loss: 0.0071 - 407ms/epoch - 18ms/step\n",
            "Epoch 9/50\n",
            "23/23 - 0s - loss: 0.0074 - val_loss: 0.0066 - 473ms/epoch - 21ms/step\n",
            "Epoch 10/50\n",
            "23/23 - 0s - loss: 0.0068 - val_loss: 0.0060 - 494ms/epoch - 21ms/step\n",
            "Epoch 11/50\n",
            "23/23 - 0s - loss: 0.0061 - val_loss: 0.0055 - 451ms/epoch - 20ms/step\n",
            "Epoch 12/50\n",
            "23/23 - 0s - loss: 0.0057 - val_loss: 0.0052 - 327ms/epoch - 14ms/step\n",
            "Epoch 13/50\n",
            "23/23 - 0s - loss: 0.0054 - val_loss: 0.0052 - 286ms/epoch - 12ms/step\n",
            "Epoch 14/50\n",
            "23/23 - 0s - loss: 0.0052 - val_loss: 0.0049 - 347ms/epoch - 15ms/step\n",
            "Epoch 15/50\n",
            "23/23 - 0s - loss: 0.0050 - val_loss: 0.0046 - 299ms/epoch - 13ms/step\n",
            "Epoch 16/50\n",
            "23/23 - 0s - loss: 0.0048 - val_loss: 0.0047 - 177ms/epoch - 8ms/step\n",
            "Epoch 17/50\n",
            "23/23 - 0s - loss: 0.0048 - val_loss: 0.0045 - 259ms/epoch - 11ms/step\n",
            "Epoch 18/50\n",
            "23/23 - 0s - loss: 0.0046 - val_loss: 0.0044 - 279ms/epoch - 12ms/step\n",
            "Epoch 19/50\n",
            "23/23 - 0s - loss: 0.0045 - val_loss: 0.0043 - 364ms/epoch - 16ms/step\n",
            "Epoch 20/50\n",
            "23/23 - 0s - loss: 0.0045 - val_loss: 0.0042 - 205ms/epoch - 9ms/step\n",
            "Epoch 21/50\n",
            "23/23 - 0s - loss: 0.0044 - val_loss: 0.0042 - 178ms/epoch - 8ms/step\n",
            "Epoch 22/50\n",
            "23/23 - 0s - loss: 0.0043 - val_loss: 0.0040 - 158ms/epoch - 7ms/step\n",
            "Epoch 23/50\n",
            "23/23 - 0s - loss: 0.0042 - val_loss: 0.0040 - 126ms/epoch - 5ms/step\n",
            "Epoch 24/50\n",
            "23/23 - 0s - loss: 0.0042 - val_loss: 0.0041 - 163ms/epoch - 7ms/step\n",
            "Epoch 25/50\n",
            "23/23 - 0s - loss: 0.0042 - val_loss: 0.0039 - 147ms/epoch - 6ms/step\n",
            "Epoch 26/50\n",
            "23/23 - 0s - loss: 0.0041 - val_loss: 0.0039 - 148ms/epoch - 6ms/step\n",
            "Epoch 27/50\n",
            "23/23 - 0s - loss: 0.0041 - val_loss: 0.0044 - 166ms/epoch - 7ms/step\n",
            "Epoch 28/50\n",
            "23/23 - 0s - loss: 0.0042 - val_loss: 0.0039 - 169ms/epoch - 7ms/step\n",
            "Epoch 29/50\n",
            "23/23 - 0s - loss: 0.0040 - val_loss: 0.0040 - 139ms/epoch - 6ms/step\n",
            "Epoch 30/50\n",
            "23/23 - 0s - loss: 0.0040 - val_loss: 0.0038 - 202ms/epoch - 9ms/step\n",
            "Epoch 31/50\n",
            "23/23 - 0s - loss: 0.0040 - val_loss: 0.0037 - 236ms/epoch - 10ms/step\n",
            "Epoch 32/50\n",
            "23/23 - 0s - loss: 0.0039 - val_loss: 0.0037 - 169ms/epoch - 7ms/step\n",
            "Epoch 33/50\n",
            "23/23 - 0s - loss: 0.0038 - val_loss: 0.0036 - 137ms/epoch - 6ms/step\n",
            "Epoch 34/50\n",
            "23/23 - 0s - loss: 0.0038 - val_loss: 0.0037 - 119ms/epoch - 5ms/step\n",
            "Epoch 35/50\n",
            "23/23 - 0s - loss: 0.0038 - val_loss: 0.0036 - 132ms/epoch - 6ms/step\n",
            "Epoch 36/50\n",
            "23/23 - 0s - loss: 0.0038 - val_loss: 0.0036 - 165ms/epoch - 7ms/step\n",
            "Epoch 37/50\n",
            "23/23 - 0s - loss: 0.0037 - val_loss: 0.0035 - 238ms/epoch - 10ms/step\n",
            "Epoch 38/50\n",
            "23/23 - 0s - loss: 0.0037 - val_loss: 0.0036 - 207ms/epoch - 9ms/step\n",
            "Epoch 39/50\n",
            "23/23 - 0s - loss: 0.0037 - val_loss: 0.0035 - 214ms/epoch - 9ms/step\n",
            "Epoch 40/50\n",
            "23/23 - 0s - loss: 0.0036 - val_loss: 0.0035 - 179ms/epoch - 8ms/step\n",
            "Epoch 41/50\n",
            "23/23 - 0s - loss: 0.0036 - val_loss: 0.0036 - 215ms/epoch - 9ms/step\n",
            "Epoch 42/50\n",
            "23/23 - 0s - loss: 0.0036 - val_loss: 0.0034 - 209ms/epoch - 9ms/step\n",
            "Epoch 43/50\n",
            "23/23 - 0s - loss: 0.0035 - val_loss: 0.0034 - 246ms/epoch - 11ms/step\n",
            "Epoch 44/50\n",
            "23/23 - 0s - loss: 0.0035 - val_loss: 0.0034 - 268ms/epoch - 12ms/step\n",
            "Epoch 45/50\n",
            "23/23 - 0s - loss: 0.0035 - val_loss: 0.0034 - 227ms/epoch - 10ms/step\n",
            "Epoch 46/50\n",
            "23/23 - 0s - loss: 0.0035 - val_loss: 0.0033 - 171ms/epoch - 7ms/step\n",
            "Epoch 47/50\n",
            "23/23 - 0s - loss: 0.0034 - val_loss: 0.0034 - 203ms/epoch - 9ms/step\n",
            "Epoch 48/50\n",
            "23/23 - 0s - loss: 0.0034 - val_loss: 0.0033 - 154ms/epoch - 7ms/step\n",
            "Epoch 49/50\n",
            "23/23 - 0s - loss: 0.0034 - val_loss: 0.0033 - 166ms/epoch - 7ms/step\n",
            "Epoch 50/50\n",
            "23/23 - 0s - loss: 0.0034 - val_loss: 0.0033 - 184ms/epoch - 8ms/step\n",
            "1dCNN autoencoder trained, with validation loss: 0.003296064445748925.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gettting the Global weights, needed for counterfactuals\n",
        "\n",
        "from _guided import get_global_weights\n",
        "from help_functions import evaluate\n",
        "pos_label = 1\n",
        "neg_label = 0\n",
        "\n",
        "step_weights = get_global_weights(\n",
        "        X,\n",
        "        y_classes,\n",
        "        cnnClassifier,\n",
        "        n_timesteps= n_timesteps,\n",
        "        n_features=n_features,\n",
        "        random_state=RANDOM_STATE,\n",
        ")\n"
      ],
      "metadata": {
        "id": "hysd9dxSsx9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step_weights"
      ],
      "metadata": {
        "id": "3WcwnNgc3RdP",
        "outputId": "24e33851-1608-4ce1-9367-a129cd5eb6cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5,tolerance=1e-6, max_iter=500, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),autoencoder = autoencoder,\n",
        "    pred_margin_weight=0.7, step_weights = step_weights, random_state= RANDOM_STATE)\n",
        "cf_model.fit(cnnClassifier)\n",
        "\n",
        "y_neg = y_classes[y_classes == 0]\n",
        "X_neg = X[y_classes == 0]\n",
        "\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses, weights = cf_model.transform(X_neg, y_neg) #self, x, pred_label\n",
        "cf_pred_labels = cnnClassifier.predict(cf_embeddings)[:,1]# predicted probabilities of CFs\n",
        "for idx in range(cf_pred_labels.shape[0]):\n",
        "  if cf_pred_labels[idx] > 0.5:\n",
        "    cf_pred_labels[idx] = 1\n",
        "  else:\n",
        "    cf_pred_labels[idx] = 0\n",
        "\n",
        "print(f'Transformation_finished with validity_score = {validity_score(y_neg,cf_pred_labels)}')"
      ],
      "metadata": {
        "id": "f-Xy39aj8q9S",
        "outputId": "0ca4569b-916c-45b1-d077-5b2bfc731fe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 samples been transformed.\n",
            "26 samples been transformed.\n",
            "51 samples been transformed.\n",
            "76 samples been transformed.\n",
            "101 samples been transformed.\n",
            "126 samples been transformed.\n",
            "151 samples been transformed.\n",
            "176 samples been transformed.\n",
            "201 samples been transformed.\n",
            "208 samples been transformed, in total.\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Transformation_finished with validity_score = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating proximity\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "total = 0\n",
        "probability = 0.5\n",
        "for idx in range(cf_embeddings.shape[0]):\n",
        "    counterfactual = cf_embeddings[idx,np.newaxis]\n",
        "    prediction = cnnClassifier.predict(counterfactual)[:, 1]\n",
        "    dist = (prediction - probability)\n",
        "    total +=dist\n",
        "mean_mse = total /cf_embeddings.shape[0]\n"
      ],
      "metadata": {
        "id": "ZkPSSHScmi2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The Mean MSE of the data is: {mean_mse} \")"
      ],
      "metadata": {
        "id": "6FXZX1A-5Er1",
        "outputId": "590ca095-9ddb-4532-9edc-9cbcaa8679be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean MSE of the data is: [0.00051351] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating proximity\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "total = 0\n",
        "probability = 0.5\n",
        "for idx in range(cf_embeddings.shape[0]):\n",
        "    counterfactual = cf_embeddings[idx,np.newaxis]\n",
        "    prediction = cnnClassifier.predict(counterfactual)[:, 1]\n",
        "    dist = abs(prediction - probability)\n",
        "    total +=dist\n",
        "mean_mse = total /cf_embeddings.shape[0]\n"
      ],
      "metadata": {
        "id": "AcUwDKnZmj6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The Absolute Mean MSE of the data is: {mean_mse} \")"
      ],
      "metadata": {
        "id": "1x5s2_8H5F3w",
        "outputId": "92239353-85a3-4fef-d289-faead5a88288",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Absolute Mean MSE of the data is: [0.00051351] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_paddings(cf_samples, padding_size):\n",
        "    if padding_size != 0:\n",
        "        # use np.squeeze() to cut the last time-series dimension, for evaluation\n",
        "        cf_samples = np.squeeze(cf_samples[:, :-padding_size, :])\n",
        "    else:\n",
        "        cf_samples = np.squeeze(cf_samples)\n",
        "    return cf_samples"
      ],
      "metadata": {
        "id": "74VVIGnzdNG3"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = remove_paddings(X, padding_size)\n",
        "cf_embeddings = remove_paddings(cf_embeddings, padding_size)\n"
      ],
      "metadata": {
        "id": "D4u5L_H5Zrx1"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Proximity\n",
        "def euclidean_distance(X, cf_samples):\n",
        "    paired_distances = np.linalg.norm(X - cf_samples, axis=1)\n",
        "    return np.mean(paired_distances)\n",
        "euclidean_distance(X_neg, cf_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50Hed3JXrm1Z",
        "outputId": "9a302b4f-1967-46ab-ee20-75e9c9e0c52a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4412798141890419"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_paddings(cf_samples, padding_size):\n",
        "    if padding_size != 0:\n",
        "        # use np.squeeze() to cut the last time-series dimension, for evaluation\n",
        "        cf_samples = np.squeeze(cf_samples[:, :-padding_size, :])\n",
        "    else:\n",
        "        cf_samples = np.squeeze(cf_samples)\n",
        "    return cf_samples"
      ],
      "metadata": {
        "id": "9MPQoXMjrFmn"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove paddings because KDE does not work with paddings.\n",
        "\n",
        "X_unpadded = remove_paddings(X, padding_size)\n",
        "cf_embeddings_unpadded = remove_paddings(cf_embeddings, padding_size)"
      ],
      "metadata": {
        "id": "dh_BVpXMrtXu"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import gaussian_kde\n",
        "diffrences_from_abnormal = []\n",
        "diffrences_from_normal = []\n",
        "for dimention in range(cf_embeddings.shape[2]):\n",
        "\n",
        "\n",
        "  abnormal_data = X[y_classes == 1][:,:,dimention]\n",
        "  normal_data = X[y_classes == 0][:,:,dimention]\n",
        "  counterf_data = cf_embeddings[:,:,dimention]\n",
        "\n",
        "  #get the kernel for every dimention of the trained\n",
        "  kernel = gaussian_kde(abnormal_data.T,bw_method=None)\n",
        "\n",
        "  #get all the log likelihoods\n",
        "  log_likelihood_abnormal = np.mean(kernel.logpdf(abnormal_data.T))\n",
        "  log_likelihood_normal = np.mean(kernel.logpdf(normal_data.T))\n",
        "  log_likelihood_counterfactual = np.mean(kernel.logpdf(counterf_data.T))\n",
        "\n",
        "  #get the diffrences from the counterfactuals\n",
        "  diff_from_abnormal = abs(log_likelihood_counterfactual-log_likelihood_abnormal)\n",
        "  diffrences_from_abnormal.append(diff_from_abnormal)\n",
        "\n",
        "  diff_from_normal = abs(log_likelihood_counterfactual-log_likelihood_normal)\n",
        "  diffrences_from_normal.append(diff_from_normal)\n",
        "\n"
      ],
      "metadata": {
        "id": "9Bb5nfXtOE4O"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(diffrences_from_normal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d4LPz8jhBve",
        "outputId": "4a83b4eb-6df6-4626-ad42-3de0cc1b41a7"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10.14190637323604, 59.36053145276334, 16.676596903506663, 16.009800043353337, 15.914253094148407, 3.3084957436863363, 14.987479240605609, 11.431553806729582, 12.850826221229624, 21.995216594113145, 10.085604616895267, 9.83738700850374, 17.424174230334017, 33.9245609690335, 59.762894464983084, 7.54800387978527, 13.018639012459815, 0.5721938614201036, 40.39350238012719, 32.39096305950366, 1.3753953888049892, 1.9422568245467886, 6.165461277482876, 6.1785447351806795, 5.474288819501908, 17.77340190528811, 15.690615477537278, 13.785216282805678]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(diffrences_from_abnormal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWvnGPiMi1Yt",
        "outputId": "10232b4f-121c-4bcc-fdef-b1798de6c9c8"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[44.212911050150126, 112.92762526917502, 73.65000590042959, 73.24704171599039, 41.43466186241061, 53.01934523248295, 72.4284511407488, 69.03285774268709, 43.31021800002591, 31.608219964543963, 44.13069128215305, 44.29242341510391, 36.63523117176335, 87.78181016291421, 113.50509568689554, 47.139258887473574, 42.10099856438231, 58.83248072223172, 101.41369303537027, 94.73161550225579, 57.502877782225994, 49.84957174575267, 47.66249700027157, 45.251459517188835, 46.59700932339416, 34.833210622336864, 36.26195917458506, 39.60060776059336]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(diffrences_from_normal))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxNyE5DOkgIo",
        "outputId": "6f3127a9-d515-4dd8-9c47-a964d4161e28"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17.000705845270215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(diffrences_from_abnormal))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YUPomtilE7p",
        "outputId": "6dda979b-5fc0-4a0f-f8c4-0d008c4eae86"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58.678351044126316\n"
          ]
        }
      ]
    }
  ]
}